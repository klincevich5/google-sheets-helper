# core/logic.py

import hashlib
from datetime import datetime, timedelta
import time
from typing import List
from core.data import return_raw_tasks, return_tracked_tables

from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from core.methods import PROCESSORS

def log_to_file(path, text):
    with open(path, "a", encoding="utf-8") as f:
        f.write(f"{datetime.now().isoformat()} ‚Äî {text}\n")

log_file = "scanner.log"

TOKEN_PATH = "token.json"  # –ø—É—Ç—å –∫ —Ç–æ–∫–µ–Ω—É

def load_credentials():
    creds = Credentials.from_authorized_user_file(TOKEN_PATH)
    service = build("sheets", "v4", credentials=creds)
    return service


def batch_get(service, spreadsheet_id, ranges, log_file):
    """ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets —Å –ø–æ–º–æ—â—å—é batchGet """
    try:
        result = service.spreadsheets().values().batchGet(  # <-- –¥–æ–±–∞–≤–ª—è–µ–º .spreadsheets()!
            spreadsheetId=spreadsheet_id,
            ranges=ranges,
            majorDimension="ROWS"
        ).execute()

        value_ranges = result.get("valueRanges", [])
        data = {}
        for value_range in value_ranges:
            range_name = value_range.get("range", "")
            values = value_range.get("values", [])
            data[range_name] = values
        return data
    except Exception as e:
        log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ batchGet: {e}")
        return {}
    
def batch_update(service, spreadsheet_id, batch_data, log_file):
    """ –û—Ç–ø—Ä–∞–≤–∫–∞ batchUpdate –∑–∞–ø—Ä–æ—Å–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏ """
    try:
        body = {
            "valueInputOption": "USER_ENTERED",
            "data": batch_data
        }
        service.spreadsheets().values().batchUpdate(
            spreadsheetId=spreadsheet_id,
            body=body
        ).execute()

        return True, None

    except Exception as e:
        log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ batchUpdate: {e}")
        return False, str(e)
    
# def RotationsInfo_scanner(self):
#     log_file = "scanner_rotationsinfo.log"

#     if not self.rotationsinfo_tasks:
#         log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è RotationsInfo.")
#         return

#     update_main_tasks = [task for task in self.rotationsinfo_tasks if task.update_group == "update_main"]
#     update_shuffle_tasks = [task for task in self.rotationsinfo_tasks if task.update_group in ("update_generic_shuffle", "update_legendz_shuffle", "update_gsbj_shuffle")]

#     if update_main_tasks:
#         self._handle_main_updates(update_main_tasks, log_file)

#     if update_shuffle_tasks:
#         self._handle_shuffle_updates(update_shuffle_tasks, log_file)

# def SheetsInfo_scanner(self):
#     log_file = "scanner_sheetsinfo.log"

#     if not self.sheetsinfo_tasks:
#         log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è SheetsInfo.")
#         return

#     self._handle_other_updates(self.sheetsinfo_tasks, log_file)


class Task:
    def __init__(self, data):
        self.id = data.get("id")
        self.name_of_process = data.get("name_of_process")
        self.source_table_type = data.get("source_table_type")
        self.source_page_name = data.get("source_page_name")
        self.source_page_area = data.get("source_page_area")
        self.scan_group = data.get("scan_group")
        self.last_scan = data.get("last_scan")
        self.scan_interval = data.get("scan_interval")
        self.scan_quantity = data.get("scan_quantity", 0)
        self.scan_failures = data.get("scan_failures", 0)
        self.hash = data.get("hash")
        self.process_data_method = data.get("process_data_method")
        self.values_json = data.get("values_json")
        self.target_table_type = data.get("target_table_type")
        self.target_page_name = data.get("target_page_name")
        self.target_page_area = data.get("target_page_area")
        self.update_group = data.get("update_group")
        self.last_update = data.get("last_update")
        self.update_quantity = data.get("update_quantity", 0)
        self.update_failures = data.get("update_failures", 0)
        self.start_row = data.get("start_row")
        self.end_row = data.get("end_row")
        self.need_update = data.get("need_update", 0)

        self.source_doc_id = None
        self.target_doc_id = None

        self.raw_values_json = None  # <=== –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö

    def is_ready_to_scan(self):
        if not self.last_scan:
            log_to_file(log_file, f"üìÖ [Task {self.id} {self.name_of_process}] –ù–µ—Ç last_scan ‚Äî –≥–æ—Ç–æ–≤–æ –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.")
            return True
        next_scan_time = self.last_scan + timedelta(seconds=self.scan_interval)
        ready = datetime.now() >= next_scan_time
        log_to_file(log_file, f"üìÖ [Task {self.id} {self.name_of_process}] Last scan: {self.last_scan}, Next scan time: {next_scan_time}, Ready: {ready}")
        return ready

    def assign_doc_ids(self, doc_id_map):
        self.source_doc_id = doc_id_map.get(self.source_table_type)
        self.target_doc_id = doc_id_map.get(self.target_table_type)
        if self.source_doc_id and self.target_doc_id:
            log_to_file(log_file, f"üîó [Task {self.name_of_process}] –ü—Ä–∏–≤—è–∑–∞–Ω—ã doc_id: source_doc_id={self.source_doc_id}, target_doc_id={self.target_doc_id}")
            return True
        else:
            log_to_file(log_file, f"‚ùå [Task {self.name_of_process}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤—è–∑–∞—Ç—å doc_id: source={self.source_table_type}, target={self.target_table_type}")
            return False

    def update_after_scan(self, success):
        previous_scan_quantity = self.scan_quantity
        previous_scan_failures = self.scan_failures
        if success:
            self.last_scan = datetime.now()
            self.scan_quantity += 1
            log_to_file(log_file, f"‚úÖ [Task {self.name_of_process}] –£—Å–ø–µ—à–Ω—ã–π —Å–∫–∞–Ω: scan_quantity {previous_scan_quantity} ‚Üí {self.scan_quantity}")
        else:
            self.scan_failures += 1
            log_to_file(log_file, f"‚ö†Ô∏è [Task {self.name_of_process}] –û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: scan_failures {previous_scan_failures} ‚Üí {self.scan_failures}")

    def process_raw_value(self):
        if not self.raw_values_json:
            log_to_file(log_file, f"‚ö™ [Task {self.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (raw_values_json –ø—É—Å—Ç).")
            return

        method_name = self.process_data_method or "process_default"
        process_func = PROCESSORS.get(method_name)

        if not process_func:
            log_to_file(log_file, f"‚ùå [Task {self.name_of_process}] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {method_name}")
            return

        try:
            processed_values = process_func(self.raw_values_json)
            self.values_json = processed_values
            log_to_file(log_file, f"üõ†Ô∏è [Task {self.name_of_process}] –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ {method_name}.")
        except Exception as e:
            log_to_file(log_file, f"‚ùå [Task {self.name_of_process}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ—Ç–æ–¥–æ–º {method_name}: {e}")

    def process_values(self):
        if not self.values_json:
            log_to_file(log_file, f"‚ö™ [Task {self.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ values_json –¥–ª—è —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return None
        processed = str(self.values_json).encode("utf-8")
        new_hash = hashlib.md5(processed).hexdigest()
        log_to_file(log_file, f"üìå [Task {self.name_of_process}] –ü–æ—Å—á–∏—Ç–∞–Ω –Ω–æ–≤—ã–π —Ö—ç—à: {new_hash}")
        return new_hash

    def check_for_update(self):
        new_hash = self.process_values()
        if new_hash and new_hash != self.hash:
            old_hash = self.hash
            self.hash = new_hash
            self.need_update = 1
            log_to_file(log_file, f"‚ôªÔ∏è [Task {self.name_of_process}] –•—ç—à –∏–∑–º–µ–Ω–∏–ª—Å—è: {old_hash} ‚Üí {new_hash}, –Ω—É–∂–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∞.\n")
        else:
            self.need_update = 0
            log_to_file(log_file, f"‚úÖ [Task {self.name_of_process}] –•—ç—à –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, –≤—ã–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n")

    def update_after_upload(self, success):
        previous_update_quantity = self.update_quantity
        previous_update_failures = self.update_failures
        if success:
            self.last_update = datetime.now()
            self.update_quantity += 1
            log_to_file(log_file, f"üì§ [Task {self.name_of_process}] –£—Å–ø–µ—à–Ω—ã–π –∞–ø–¥–µ–π—Ç: update_quantity {previous_update_quantity} ‚Üí {self.update_quantity}")
        else:
            self.update_failures += 1
            log_to_file(log_file, f"‚ùå [Task {self.name_of_process}] –û—à–∏–±–∫–∞ –∞–ø–¥–µ–π—Ç–∞: update_failures {previous_update_failures} ‚Üí {self.update_failures}")

class TaskManager:
    def __init__(self):
        self.tasks = []
        self.doc_id_map = self.get_current_month_id()
        self.service = load_credentials()

    def get_active_tabs(self):
        now = datetime.now()
        hour = now.hour
        tab_list = []

        if 9 <= hour < 19:
            tab_list.append(f"DAY {now.day}")
        elif 19 <= hour < 21:
            tab_list.append(f"DAY {now.day}")
            tab_list.append(f"NIGHT {now.day}")
        elif 21 <= hour <= 23:
            tab_list.append(f"NIGHT {now.day}")
        elif 0 <= hour < 7:
            yesterday = now - timedelta(days=1)
            tab_list.append(f"NIGHT {yesterday.day}")
        elif 7 <= hour < 9:
            yesterday = now - timedelta(days=1)
            tab_list.append(f"DAY {now.day}")
            tab_list.append(f"NIGHT {yesterday.day}")

        # –î–ª—è —Ç–µ—Å—Ç–æ–≤
        tab_list = ["DAY 1"]
        return tab_list

    def load_active_tasks(self, active_tabs):
        raw_tasks = return_raw_tasks()
        # return [Task(data) for data in raw_tasks if data.get("source_page_name") in active_tabs]
        return [Task(data) for data in raw_tasks]

    def get_current_month_id(self):
        today = datetime.now().date()
        tracked_tables = return_tracked_tables()
        result = {}
        for table in tracked_tables:
            valid_from = datetime.strptime(table["valid_from"], "%d.%m.%Y").date()
            valid_to = datetime.strptime(table["valid_to"], "%d.%m.%Y").date()
            if valid_from <= today <= valid_to:
                result[table["table_type"]] = table["spreadsheet_id"]
        return result

############################################################################################################################################################
#         log_to_file(log_file, "=== üõ†Ô∏è –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è ==="
############################################################################################################################################################

    def scan_phase(self):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "=== üöÄ –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è ===")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

        active_tabs = self.get_active_tabs()
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, f"üìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∞–∫—Ç–∏–≤–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏: {active_tabs}")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")
        self.tasks = self.load_active_tasks(active_tabs)

        if not self.tasks:
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è —Ç–µ–∫—É—â–∏—Ö –≤–∫–ª–∞–¥–æ–∫.")
            log_to_file(log_file, "")
            log_to_file(log_file, "=" * 100)
            return
        
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, f"üü¢ –ù–∞–π–¥–µ–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á: {len(self.tasks)}")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

        ready_tasks = [task for task in self.tasks if task.is_ready_to_scan()]
        if not ready_tasks:
            log_to_file(log_file, "")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "‚ö†Ô∏è –ù–µ—Ç –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.")
            log_to_file(log_file, "")
            log_to_file(log_file, "=" * 100)
            self.tasks = []
            return
        else:
            log_to_file(log_file, "")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, f"üü¢ –ù–∞–π–¥–µ–Ω–æ {len(ready_tasks)} –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "")

        scan_groups = {}
        for task in ready_tasks:
            if not task.assign_doc_ids(self.doc_id_map):
                continue
            scan_groups.setdefault(task.scan_group, []).append(task)
        log_to_file(log_file, "")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, f"üü¢ –ù–∞–π–¥–µ–Ω–æ {len(scan_groups)} –≥—Ä—É–ø–ø –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

        self.tasks = []  # –û—á–∏—â–∞–µ–º, —á—Ç–æ–±—ã –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ

        for group, tasks in scan_groups.items():
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, f"üîç [–ì—Ä—É–ø–ø–∞ {group}] –ù–∞—á–∞–ª–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è {len(tasks)} –∑–∞–¥–∞—á")
            log_to_file(log_file, "")

            try:
                unique_ranges = list({f"{task.source_page_name}!{task.source_page_area}" for task in tasks})
                spreadsheet_id = tasks[0].source_doc_id

                log_to_file(log_file, f"üîÑ –ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –∏–∑ {spreadsheet_id} –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: {unique_ranges}")

                response_data = batch_get(self.service, spreadsheet_id, unique_ranges, log_file)

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–≤–µ—Ç
                normalized_response = {}
                for k, v in response_data.items():
                    clean_key = k.replace("'", "")
                    sheet_name, cells_range = clean_key.split("!")
                    normalized_response[(sheet_name, cells_range)] = v

                log_to_file(log_file, f"üîÑ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {list(normalized_response.keys())}")
                log_to_file(log_file, "")

                successful_tasks = []

                for task in tasks:
                    expected_sheet = task.source_page_name
                    expected_area = task.source_page_area.split(":")[0]  # –±–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä "D"

                    matched = None
                    for (sheet_name, cells_range), values in normalized_response.items():
                        if sheet_name == expected_sheet and cells_range.startswith(expected_area):
                            matched = values
                            break

                    if matched:
                        task.raw_values_json = matched
                        task.update_after_scan(success=True)
                        successful_tasks.append(task)
                    else:
                        task.update_after_scan(success=False)

                self.tasks.extend(successful_tasks)

                if successful_tasks:
                    log_to_file(log_file, "")
                    log_to_file(log_file, f"‚úÖ [–ì—Ä—É–ø–ø–∞ {group}] –£—Å–ø–µ—à–Ω–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {len(successful_tasks)} –∑–∞–¥–∞—á")
                else:
                    log_to_file(log_file, "")
                    log_to_file(log_file, f"‚ùå [–ì—Ä—É–ø–ø–∞ {group}] –í—Å–µ –∑–∞–¥–∞—á–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –æ—à–∏–±–∫–æ–π.")

            except Exception as e:
                for task in tasks:
                    task.update_after_scan(success=False)
                log_to_file(log_file, "")
                log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –≥—Ä—É–ø–ø–µ {group}: {e}")

            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "")


############################################################################################################################################################
#         log_to_file(log_file, "=== üõ†Ô∏è –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ==="
############################################################################################################################################################

    def process_phase(self):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "=== üõ†Ô∏è –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

        if not self.tasks:
            log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            log_to_file(log_file, "")
            return

        success_count = 0
        failure_count = 0

        for task in self.tasks:
            try:
                task.process_raw_value()
                try:
                    task.check_for_update()
                    success_count += 1
                except Exception as e:
                    failure_count += 1
                    log_to_file(log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            except Exception as e:
                failure_count += 1
                log_to_file(log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

        log_to_file(log_file, "")
        log_to_file(log_file, f"‚úÖ –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ: {success_count}, –û—à–∏–±–æ–∫: {failure_count}")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

############################################################################################################################################################
#         log_to_file(log_file, "=== üõ†Ô∏è –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ==="
############################################################################################################################################################

    def update_phase(self):
        log_to_file("scanner.log", "=" * 100)
        log_to_file("scanner.log", "=== üîÑ –°—Ç–∞—Ä—Ç —Ñ–∞–∑—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ===")
        log_to_file("scanner.log", "=" * 100)
        log_to_file("scanner.log", "")

        if not self.tasks:
            log_to_file("scanner.log", "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.")
            log_to_file("scanner.log", "=" * 100)
            log_to_file("scanner.log", "")
            return

        self.rotationsinfo_tasks = []
        self.sheetsinfo_tasks = []

        for task in self.tasks:
            if task.source_table == "RotationsInfo":
                self.rotationsinfo_tasks.append(task)
            elif task.source_table == "SheetsInfo":
                self.sheetsinfo_tasks.append(task)
            else:
                log_to_file("scanner.log", f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ç–∞–±–ª–∏—Ü—ã: {task.source_table}")

        import threading

        thread_rotationsinfo = threading.Thread(target=self.RotationsInfo_scanner)
        thread_sheetsinfo = threading.Thread(target=self.SheetsInfo_scanner)

        thread_rotationsinfo.start()
        thread_sheetsinfo.start()

        thread_rotationsinfo.join()
        thread_sheetsinfo.join()

        log_to_file("scanner.log", "=" * 100)
        log_to_file("scanner.log", "‚úÖ –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        log_to_file("scanner.log", "=" * 100)
        log_to_file("scanner.log", "")

    def _handle_main_updates(self, tasks, log_file):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "üîÑ –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: update_main")
        log_to_file(log_file, "")

        try:
            # –ó–¥–µ—Å—å —Ç–≤–æ—è –ª–æ–≥–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è MAIN
            self.import_main_data(tasks)

            for task in tasks:
                task.update_after_upload(success=True)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞—á update_main")
            time.sleep(5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API

        except Exception as e:
            for task in tasks:
                task.update_after_upload(success=False)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ update_main: {e}")

        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")


    def _handle_shuffle_updates(self, tasks, log_file):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "üîÑ –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: update_shuffle")
        log_to_file(log_file, "")

        try:
            # –ó–¥–µ—Å—å —Ç–≤–æ—è –ª–æ–≥–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è SHUFFLE
            self.import_shuffle_data(tasks)

            for task in tasks:
                task.update_after_upload(success=True)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞—á update_shuffle")
            time.sleep(5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API

        except Exception as e:
            for task in tasks:
                task.update_after_upload(success=False)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ update_shuffle: {e}")

        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")


    def _handle_other_updates(self, tasks, log_file):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "üîÑ –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: –¥—Ä—É–≥–∏–µ –≥—Ä—É–ø–ø—ã")
        log_to_file(log_file, "")

        try:
            # –ó–¥–µ—Å—å —Ç–≤–æ—è –ª–æ–≥–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è –ø—Ä–æ—á–∏—Ö –∑–∞–¥–∞—á
            self.import_other_data(tasks)

            for task in tasks:
                task.update_after_upload(success=True)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞—á (–¥—Ä—É–≥–∏–µ –≥—Ä—É–ø–ø—ã)")
            time.sleep(5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API

        except Exception as e:
            for task in tasks:
                task.update_after_upload(success=False)

            log_to_file(log_file, "")
            log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥—Ä—É–≥–∏—Ö –≥—Ä—É–ø–ø: {e}")

        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")

    # === –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ (–ø–æ–∫–∞ –º–æ–∂–Ω–æ –ø—É—Å—Ç—ã–º–∏ —Å–¥–µ–ª–∞—Ç—å) ===


    def import_main_data(self, tasks):
        
        """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è update_main"""
        
        ROTATION_ORDER = [
            "SHUFFLE Main",
            "VIP Main",
            "TURKISH Main",
            "GENERIC Main",
            "GSBJ Main",
            "LEGENDZ Main",
            "TRI-STAR Main",
            "TritonRL Main",
        ]

        log_to_file(log_file, "=" * 50)
        log_to_file(log_file, "")
        log_to_file(log_file, "üîÑ –°—Ç–∞—Ä—Ç –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä—É–ø–ø—ã 'update_main'.")
        log_to_file(log_file, "")

        if not tasks:
            log_to_file(log_file, "‚ö†Ô∏è –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è update_main.")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–¥–∞—á–∏, —Ç—Ä–µ–±—É—é—â–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        need_update_tasks = [task for task in tasks if task.need_update == 1]
        if not need_update_tasks:
            log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø–µ update_main.")
            return

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        task_map = {task.name_of_process: task for task in tasks}
        sorted_tasks = []

        for name in ROTATION_ORDER:
            if name in task_map:
                sorted_tasks.append(task_map[name])
            else:
                log_to_file(log_file, f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Ä–µ–¥–∏ –∑–∞–¥–∞—á.")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
        all_values = []
        for task in sorted_tasks:
            if task.values_json:
                all_values.extend(task.values_json)
                all_values.append(["" * 23])  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ä–æ—Ç–∞—Ü–∏—è–º–∏
            else:
                log_to_file(log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏.")

        if all_values and all_values[-1] == []:
            all_values.pop()  # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å –≤ –∫–æ–Ω—Ü–µ

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        if len(all_values) < 100:
            empty_rows = 100 - len(all_values)
            all_values.extend([[] for _ in range(empty_rows)])
            log_to_file(log_file, f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω—ã {empty_rows} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –¥–æ 100.")
        elif len(all_values) > 100:
            all_values = all_values[:100]
            log_to_file(log_file, "‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω–æ –¥–æ 100 —Å—Ç—Ä–æ–∫.")

        spreadsheet_id = sorted_tasks[0].target_doc_id
        target_page_name = sorted_tasks[0].target_page_name
        target_page_area = sorted_tasks[0].target_page_area
        insert_range = f"{target_page_name}!{target_page_area}"

        batch_data = [{
            "range": insert_range,
            "values": all_values
        }]

        success, error = batch_update(self.service, spreadsheet_id, batch_data, log_file)

        if success:
            log_to_file(log_file, "‚úÖ –£—Å–ø–µ—à–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ –≤—Å–µ—Ö —Ä–æ—Ç–∞—Ü–∏–π –≤ update_main.")
            for task in need_update_tasks:
                task.update_after_upload(success=True)
        else:
            log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ update_main: {error}")
            for task in need_update_tasks:
                task.update_after_upload(success=False)

        log_to_file(log_file, "=" * 50)
        log_to_file(log_file, "")


    def import_shuffle_data(self, tasks):
        """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è shuffle –≥—Ä—É–ø–ø —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ update_group."""
        if not tasks:
            log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ shuffle.")
            return

        log_to_file(log_file, "=" * 50)
        log_to_file(log_file, "üîÑ –°—Ç–∞—Ä—Ç –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä—É–ø–ø—ã 'shuffle_rotation'.")
        log_to_file(log_file, "")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ update_group
        update_groups = {}
        for task in tasks:
            update_groups.setdefault(task.update_group, []).append(task)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–π batchUpdate
        batch_data = []

        for group_name, group_tasks in update_groups.items():
            log_to_file(log_file, "=" * 50)
            log_to_file(log_file, "")
            log_to_file(log_file, f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥–≥—Ä—É–ø–ø—ã: {group_name} ({len(group_tasks)} –∑–∞–¥–∞—á)")
            log_to_file(log_file, "")

            if not group_tasks:
                log_to_file(log_file, f"‚ö†Ô∏è –ù–µ—Ç –∑–∞–¥–∞—á –≤ –ø–æ–¥–≥—Ä—É–ø–ø–µ {group_name}.")
                continue

            spreadsheet_id = group_tasks[0].target_doc_id
            page_name = group_tasks[0].target_page_name
            page_area = group_tasks[0].target_page_area

            all_page_values = batch_get(self.service, spreadsheet_id, [page_area], log_file)
            sheet_values = next(iter(all_page_values.values()), [])

            shift_row_index = None
            for idx, row in enumerate(sheet_values):
                if row and isinstance(row[0], str) and "shift:" in row[0].lower():
                    shift_row_index = idx + 1
                    break

            if shift_row_index is None:
                log_to_file(log_file, f"‚ùå –°—Ç—Ä–æ–∫–∞ 'shift:' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ –ª–∏—Å—Ç–µ {page_name}.")
                continue

            start_row = shift_row_index
            end_row = start_row + 5
            insert_range = f"{page_name}!D{start_row + 1}:AC{end_row + 1}"  # +1 —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏

            log_to_file(log_file, f"üìç –ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ 'shift:' –Ω–∞ {shift_row_index + 1}-–π —Å—Ç—Ä–æ–∫–µ. –í—Å—Ç–∞–≤–∫–∞ –≥—Ä—É–ø–ø—ã {group_name} –≤ –¥–∏–∞–ø–∞–∑–æ–Ω {insert_range}.")
            log_to_file(log_file, f"json: {len(group_tasks[0].values_json)} —Å—Ç—Ä–æ–∫")
            log_to_file(log_file, "")

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ values –∏–∑ –∑–∞–¥–∞—á
            all_values = []
            for task in group_tasks:
                if task.values_json:
                    all_values.extend(task.values_json)
                else:
                    log_to_file(log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏.")

            if not all_values:
                log_to_file(log_file, f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ –ø–æ–¥–≥—Ä—É–ø–ø–µ {group_name}.")
                continue

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π batchUpdate –Ω–∞ –∫–∞–∂–¥—É—é –ø–æ–¥–≥—Ä—É–ø–ø—É
            batch_data = [{
                "range": insert_range,
                "values": all_values
            }]

            success, error = batch_update(self.service, spreadsheet_id, batch_data, log_file)

            if success:
                log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–≥—Ä—É–ø–ø—ã {group_name}.")
                for task in group_tasks:
                    task.update_after_upload(success=True)
            else:
                log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –ø–æ–¥–≥—Ä—É–ø–ø—ã {group_name}: {error}")
                for task in group_tasks:
                    task.update_after_upload(success=False)

            log_to_file(log_file, "=" * 50)
            log_to_file(log_file, "")

        log_to_file(log_file, "‚úÖ –ò–º–ø–æ—Ä—Ç shuffle_rotation –∑–∞–≤–µ—Ä—à—ë–Ω.")
        log_to_file(log_file, "=" * 50)
        log_to_file(log_file, "")


    def import_other_data(self, other_tasks: List[Task]):
        """ –ò–º–ø–æ—Ä—Ç –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á —Å —É—á–µ—Ç–æ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ –æ—à–∏–±–æ–∫ """

        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "üîÑ –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: –¥—Ä—É–≥–∏–µ –≥—Ä—É–ø–ø—ã")
        log_to_file(log_file, "")

        if not other_tasks:
            log_to_file(log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –≥—Ä—É–ø–ø–∞—Ö.")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "")
            return

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ update_group
        update_groups = {}
        for task in other_tasks:
            update_groups.setdefault(task.update_group, []).append(task)

        log_to_file(log_file, "üîÑ –°—Ç–∞—Ä—Ç batchUpdate –¥–ª—è –≥—Ä—É–ø–ø—ã '–¥—Ä—É–≥–∏–µ –∑–∞–¥–∞—á–∏'.")

        for group_name, group_tasks in update_groups.items():
            log_to_file(log_file, f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã: {group_name} ({len(group_tasks)} –∑–∞–¥–∞—á)")

            spreadsheet_id = group_tasks[0].target_doc_id

            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batchUpdate
            batch_data = []
            for task in group_tasks:
                if task.values_json:
                    batch_data.append({
                        "range": f"{task.target_page_name}!{task.target_page_area}",
                        "values": task.values_json
                    })
                else:
                    log_to_file(log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞.")

            if not batch_data:
                log_to_file(log_file, f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –≥—Ä—É–ø–ø–µ {group_name}.")
                continue

            # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å
            success, error = batch_update(self.service, spreadsheet_id, batch_data, log_file)

            if success:
                log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ –≥—Ä—É–ø–ø–µ {group_name} –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º.")
            else:
                log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—â–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≥—Ä—É–ø–ø—ã {group_name}: {error}")
                log_to_file(log_file, f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ—à—Ç—É—á–Ω–æ–º—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é –∑–∞–¥–∞—á –≥—Ä—É–ø–ø—ã {group_name}.")

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ –ø–æ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ
                for task in group_tasks:
                    if not task.values_json:
                        continue

                    single_range = f"{task.target_page_name}!{task.target_page_area}"
                    single_data = [{
                        "range": single_range,
                        "values": task.values_json
                    }]

                    single_success, single_error = batch_update(self.service, task.target_doc_id, single_data, log_file)

                    if single_success:
                        log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ [Task {task.name_of_process}] –æ—Ç–¥–µ–ª—å–Ω–æ.")
                    else:
                        log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ [Task {task.name_of_process}]: {single_error}")

            log_to_file(log_file, "")

        log_to_file(log_file, "‚úÖ –ò–º–ø–æ—Ä—Ç –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á –∑–∞–≤–µ—Ä—à—ë–Ω.")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")


    def start(self):
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "=== ‚ñ∂Ô∏è –°—Ç–∞—Ä—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å–∫–∞–Ω–µ—Ä–∞ ===")
        log_to_file(log_file, "=" * 100)
        log_to_file(log_file, "")
        while True:
            self.scan_phase()
            self.process_phase()
            self.update_phase()
            log_to_file(log_file, "")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞...")
            log_to_file(log_file, "=" * 100)
            log_to_file(log_file, "")
            time.sleep(60)


if __name__ == "__main__":
    manager = TaskManager()
    manager.start()
