# core/data.py

from datetime import datetime, timedelta
from core.task_model import Task
from sqlalchemy import text

from database.db_models import TrackedTables, TaskTemplate, RotationsInfo, SheetsInfo
from core.task_model import Task
from database.session import get_session
from core.time_provider import TimeProvider
from utils.logger import (
    log_info, log_success, log_error, log_section, log_separator
)

def return_tracked_tables(session) -> dict:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ table_type -> spreadsheet_id Ð¸Ð· TrackedTables"""
    today = TimeProvider.now().date()
    tables = session.query(TrackedTables).all()
    return {
        table.table_type: table.spreadsheet_id
        for table in tables
        if table.valid_from <= today <= table.valid_to
    }

def get_active_tabs(current_time=None):
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð²ÐºÐ»Ð°Ð´ÐºÐ¸ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
    current_time = current_time or TimeProvider.now()
    day = current_time.day
    hour = current_time.hour
    prev_day = (current_time - timedelta(days=1))

    if 9 <= hour < 19:
        return [f"DAY {day}"]
    elif 19 <= hour < 21:
        return [f"DAY {day}", f"NIGHT {day}"]
    elif 21 <= hour <= 23:
        return [f"NIGHT {day}"]
    elif 0 <= hour < 7:
        # ÐÐµ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°Ñ‚ÑŒ NIGHT Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ³Ð¾ Ð¼ÐµÑÑÑ†Ð°
        if prev_day.month != current_time.month:
            return []
        return [f"NIGHT {prev_day.day}"]
    elif 7 <= hour < 9:
        # ÐÐµ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°Ñ‚ÑŒ NIGHT Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ³Ð¾ Ð¼ÐµÑÑÑ†Ð°
        if prev_day.month != current_time.month:
            return [f"DAY {day}"]
        return [f"DAY {day}", f"NIGHT {prev_day.day}"]
    return []

def parse_datetime(value):
    """ÐŸÐ°Ñ€ÑÐ¸Ñ‚ Ð´Ð°Ñ‚Ñƒ Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð¸Ð· ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð¸Ð»Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ñ‚Ñ‹ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ñ‚Ð°Ð¹Ð¼Ð·Ð¾Ð½Ñ‹"""
    tz = TimeProvider.timezone()
    if not value:
        return datetime.min.replace(tzinfo=tz)
    if isinstance(value, str):
        try:
            value = datetime.fromisoformat(value)
        except ValueError:
            return datetime.min.replace(tzinfo=tz)
    if getattr(value, 'tzinfo', None) is None or isinstance(getattr(value, 'tzinfo', None), str):
        return value.replace(tzinfo=tz)
    return value

def build_task(row, now, source_table):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹"""
    task = Task({
        "id": row.id,
        "is_active": row.is_active,
        "related_month": row.related_month,
        "name_of_process": row.name_of_process,
        "source_table_type": row.source_table_type,
        "source_page_name": getattr(row, "source_page_name", None),
        "source_page_area": row.source_page_area,
        "scan_group": row.scan_group,
        "last_scan": row.last_scan,
        "scan_interval": row.scan_interval,
        "scan_quantity": row.scan_quantity,
        "scan_failures": row.scan_failures,
        "hash": row.hash,
        "process_data_method": row.process_data_method,
        "values_json": row.values_json,
        "target_table_type": row.target_table_type,
        "target_page_name": row.target_page_name,
        "target_page_area": row.target_page_area,
        "update_group": row.update_group,
        "last_update": row.last_update,
        "update_quantity": row.update_quantity,
        "update_failures": row.update_failures
    })
    task.source_table = source_table
    return task

def get_related_month(now_time=None):
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ related_month Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸:
    - ÐµÑÐ»Ð¸ ÑÐµÐ¹Ñ‡Ð°Ñ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 9 Ñ‡Ð°ÑÐ¾Ð² Ð¼ÐµÑÑÑ†Ð° Ð¸ ÑÑ‚Ð¾ Ð½Ð¾Ñ‡Ð½Ð°Ñ ÑÐ¼ÐµÐ½Ð° (0:00-8:59), related_month â€” Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¼ÐµÑÑÑ†
    - Ð¸Ð½Ð°Ñ‡Ðµ related_month â€” Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ð¼ÐµÑÑÑ†
    """
    now_time = now_time or TimeProvider.now()
    if now_time.day == 1 and now_time.hour < 8:
        # ÐŸÑ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¼ÐµÑÑÑ†
        prev_month = (now_time.replace(day=1) - timedelta(days=1)).replace(day=1)
        return prev_month.date()
    return now_time.replace(day=1).date()

def load_rotationsinfo_tasks(session, log_file):
    log_section(log_file, "define_tasks", "ðŸ”¼ Ð¤Ð°Ð·Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡ (RotationsInfo)")
    now_time = TimeProvider.now()
    related_month = get_related_month(now_time)
    active_tabs = get_active_tabs(now_time)
    log_info(log_file, "define_tasks", None, "now", f"ðŸ•’ Ð¡ÐµÐ¹Ñ‡Ð°Ñ: {now_time}. related_month: {related_month}")
    log_info(log_file, "define_tasks", None, "active_tabs", f"ðŸ“„ ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÐ¼ÐµÐ½Ñ‹: {active_tabs}")

    try:
        templates = session.query(TaskTemplate).filter_by(source_table="RotationsInfo").all()
        template_names = [tmpl.name_of_process for tmpl in templates]
        log_info(log_file, "define_tasks", None, "templates", f"ðŸ“š ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {len(templates)}")

        all_tasks = session.query(RotationsInfo).filter(
            RotationsInfo.related_month == related_month,
            RotationsInfo.name_of_process.in_(template_names),
            RotationsInfo.source_page_name.in_(active_tabs)
        ).all()
        log_info(log_file, "define_tasks", None, "db_tasks", f"ðŸ“¦ ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð´Ð°Ñ‡ Ð² Ð‘Ð” Ð´Ð»Ñ related_month={related_month}, active_tabs={active_tabs}: {len(all_tasks)}")

        existing = {
            (t.name_of_process, t.source_page_name): t
            for t in all_tasks
        }

        new_tasks = []
        created_count = 0
        for tmpl in templates:
            for tab in active_tabs:
                key = (tmpl.name_of_process, tab)
                if key not in existing:
                    try:
                        new_task = RotationsInfo(
                            name_of_process=tmpl.name_of_process,
                            source_table_type=tmpl.source_table_type,
                            source_page_name=tab,
                            source_page_area=tmpl.source_page_area,
                            scan_group=tmpl.scan_group,
                            scan_interval=tmpl.scan_interval,
                            process_data_method=tmpl.process_data_method,
                            target_table_type=tmpl.target_table_type,
                            target_page_name=tab,
                            target_page_area=tmpl.target_page_area,
                            update_group=tmpl.update_group,
                            is_active=1,
                            related_month=related_month,
                            scan_quantity=0,
                            scan_failures=0,
                            update_quantity=0,
                            update_failures=0,
                            last_scan=None,
                            last_update=None,
                            hash=None,
                            values_json=None
                        )
                        new_tasks.append(new_task)
                        existing[key] = new_task
                        created_count += 1
                        log_success(log_file, "define_tasks", tmpl.name_of_process, "created", f"Ð—Ð°Ð´Ð°Ñ‡Ð° '{tmpl.name_of_process}' Ð´Ð»Ñ ÑÐ¼ÐµÐ½Ñ‹ '{tab}' ÑÐ¾Ð·Ð´Ð°Ð½Ð°.")
                    except Exception as e:
                        log_error(log_file, "define_tasks", tmpl.name_of_process, "fail", f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸: {e}")
        log_info(log_file, "define_tasks", None, "new_tasks", f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {created_count}")

        if new_tasks:
            session.bulk_save_objects(new_tasks)
            session.commit()
            log_success(log_file, "define_tasks", None, "saved", f"ðŸ“¥ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {len(new_tasks)}")

        active_tasks = session.query(RotationsInfo).filter(
            RotationsInfo.related_month == related_month,
            RotationsInfo.name_of_process.in_(template_names),
            RotationsInfo.source_page_name.in_(active_tabs),
            RotationsInfo.is_active == 1
        ).all()
        log_info(log_file, "define_tasks", None, "active", f"âœ… ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {len(active_tasks)}")

        tasks = []
        for task in active_tasks:
            try:
                last_scan = parse_datetime(task.last_scan)
                next_scan = last_scan + timedelta(seconds=task.scan_interval)
                minutes_left = int((next_scan - now_time).total_seconds() / 60)
                log_info(log_file, "define_tasks", task.name_of_process, "ready",
                    f"[âœ…READY] Task '{task.name_of_process} {task.source_page_name}' | "
                    f"Last scan: {last_scan:%Y-%m-%d %H:%M:%S} | "
                    f"Interval: {task.scan_interval // 60} min | "
                    f"In: {minutes_left} min | "
                    f"Next scan at: {next_scan:%Y-%m-%d %H:%M} | "
                    f"Now: {now_time:%Y-%m-%d %H:%M:%S}"
                )
                built_task = build_task(task, now_time, "RotationsInfo")
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° assign_doc_ids (ÐµÑÐ»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ)
                if hasattr(built_task, 'assign_doc_ids'):
                    doc_id_map = getattr(task, 'doc_id_map', None)
                    if doc_id_map:
                        ok = built_task.assign_doc_ids(doc_id_map)
                        log_info(log_file, "define_tasks", task.name_of_process, "assign_doc_ids", f"assign_doc_ids Ð²ÐµÑ€Ð½ÑƒÐ»: {ok}")
                tasks.append(built_task)
            except Exception as e:
                log_error(log_file, "define_tasks", task.name_of_process, "fail", f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð´Ð°Ñ‡Ð¸: {e}")
        log_success(log_file, "define_tasks", None, "done", f"âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾. Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð´Ð°Ñ‡ Ðº Ð·Ð°Ð¿ÑƒÑÐºÑƒ: {len(tasks)}")
        return tasks
    except Exception as e:
        session.rollback()
        raise
    finally:
        session.close()
        
def load_sheetsinfo_tasks(session, log_file):
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· SheetsInfo, ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð², Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÑ‚ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Task-Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð², Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ñ… Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸ÑŽ.
    """
    log_section(log_file, "define_tasks", "ðŸ”¼ Ð¤Ð°Ð·Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡ (SheetsInfo)")
    now_time = TimeProvider.now()
    related_month = get_related_month(now_time)
    log_info(log_file, "define_tasks", None, "now", f"ðŸ•’ Ð¡ÐµÐ¹Ñ‡Ð°Ñ: {now_time}. related_month: {related_month}")

    try:
        # Ð¨Ð°Ð³ 1: Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñ‹
        templates = session.query(TaskTemplate).filter_by(source_table="SheetsInfo").all()
        template_names = [tmpl.name_of_process for tmpl in templates]
        log_info(log_file, "define_tasks", None, "templates", f"ðŸ“š ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {len(templates)}")

        # Ð¨Ð°Ð³ 2: Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ð‘Ð”
        all_tasks = session.query(SheetsInfo).filter(
            SheetsInfo.related_month == related_month,
            SheetsInfo.name_of_process.in_(template_names)
        ).all()
        log_info(log_file, "define_tasks", None, "db_tasks",
                f"ðŸ“¦ ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð´Ð°Ñ‡ Ð² Ð‘Ð” Ð´Ð»Ñ related_month={related_month}: {len(all_tasks)}")

        existing = {t.name_of_process: t for t in all_tasks}
        new_tasks = []
        created_count = 0

        # Ð¨Ð°Ð³ 3: ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        for tmpl in templates:
            if tmpl.name_of_process not in existing:
                try:
                    new_task = SheetsInfo(
                        name_of_process=tmpl.name_of_process,
                        source_table_type=tmpl.source_table_type,
                        source_page_name=tmpl.source_page_name,
                        source_page_area=tmpl.source_page_area,
                        scan_group=tmpl.scan_group,
                        scan_interval=tmpl.scan_interval,
                        process_data_method=tmpl.process_data_method,
                        target_table_type=tmpl.target_table_type,
                        target_page_name=tmpl.target_page_name,
                        target_page_area=tmpl.target_page_area,
                        update_group=tmpl.update_group,
                        is_active=1,
                        related_month=related_month,
                        scan_quantity=0,
                        scan_failures=0,
                        update_quantity=0,
                        update_failures=0,
                        last_scan=None,
                        last_update=None,
                        hash=None,
                        values_json=None
                    )
                    new_tasks.append(new_task)
                    existing[tmpl.name_of_process] = new_task
                    created_count += 1
                    log_success(log_file, "define_tasks", tmpl.name_of_process, "created",
                                f"Ð—Ð°Ð´Ð°Ñ‡Ð° '{tmpl.name_of_process}' ÑÐ¾Ð·Ð´Ð°Ð½Ð°.")
                except Exception as e:
                    log_error(log_file, "define_tasks", getattr(tmpl, 'name_of_process', None),
                            "fail", "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸", exc=e)

        log_info(log_file, "define_tasks", None, "new_tasks", f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {created_count}")

        if new_tasks:
            try:
                session.bulk_save_objects(new_tasks, return_defaults=True)
                session.commit()
                log_success(log_file, "define_tasks", None, "saved",
                            f"ðŸ“¥ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {len(new_tasks)}")
            except Exception as e:
                session.rollback()
                log_error(log_file, "define_tasks", None, "db_commit",
                        "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡", exc=e)

        # Ð¨Ð°Ð³ 4: Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ…
        active_tasks = session.query(SheetsInfo).filter(
            SheetsInfo.related_month == related_month,
            SheetsInfo.name_of_process.in_(template_names),
            SheetsInfo.is_active == 1
        ).order_by(SheetsInfo.name_of_process.asc()).all()
        log_info(log_file, "define_tasks", None, "active",
                f"âœ… ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡: {len(active_tasks)}")

        # Ð¨Ð°Ð³ 5: Ð¾Ñ‚Ð±Ð¾Ñ€ Ð¿Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ + Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Task
        tasks = []
        for task_obj in active_tasks:
            try:
                built_task = Task(task_obj.__dict__)

                if not built_task.is_ready_to_scan():
                    next_scan = built_task.last_scan + timedelta(seconds=built_task.scan_interval)
                    minutes_left = int((next_scan - now_time).total_seconds() / 60)
                    log_info(log_file, "define_tasks", built_task.name_of_process, "skip",
                            f"[â³SKIP] Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ Ñ€Ð°Ð½Ð¾. Next scan at: {next_scan:%Y-%m-%d %H:%M}, in {minutes_left} min.")
                    continue

                log_info(log_file, "define_tasks", built_task.name_of_process, "ready",
                        f"[âœ…READY] Task '{built_task.name_of_process} {built_task.source_page_name}' | "
                        f"Last scan: {built_task.last_scan} | "
                        f"Interval: {built_task.scan_interval // 60} min")

                tasks.append(built_task)

            except Exception as e:
                log_error(log_file, "define_tasks", getattr(task_obj, 'name_of_process', None),
                        "fail", "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð´Ð°Ñ‡Ð¸", exc=e)

        log_success(log_file, "define_tasks", None, "done",
                    f"âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾. Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð´Ð°Ñ‡ Ðº Ð·Ð°Ð¿ÑƒÑÐºÑƒ: {len(tasks)}")
        return tasks

    except Exception as e:
        session.rollback()
        log_error(log_file, "define_tasks", None, "fatal",
                "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸", exc=e)
        raise

    finally:
        session.close()


def refresh_materialized_views(session, updated_groups: set, log_file=None):
    """ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹."""

    from sqlalchemy import text
    views = {
        "update_qa_list_db": "mv_qa_list",
        "update_mistakes_in_db": "mv_mistakes",
        "feedback_status_update": "mv_feedbacks",
        "update_schedule_OT": "mv_schedule_ot",
    }

    for group_name in updated_groups:
        view_name = views.get(group_name)
        if view_name:
            try:
                session.execute(text(f"REFRESH MATERIALIZED VIEW CONCURRENTLY {view_name}"))
                log_info(log_file, "refresh_views", view_name, "success", f"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»Ñ‘Ð½: {view_name}")
            except Exception as e:
                log_error(log_file, "refresh_views", view_name, "fail", f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸ {view_name}: {e}")