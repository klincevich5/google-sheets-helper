# scanners/sheetsinfo_scanner.py

import time
import sqlite3
from collections import defaultdict

from bot.settings_access import is_scanner_enabled
from core.config import SHEETSINFO_LOG, SHEETSINFO_TOKEN, SHEETINFO_INTERVAL, DB_PATH
from core.data import load_sheetsinfo_tasks
from database.database import insert_usage
from utils.logger import log_to_file, log_separator, log_section
from core.token_manager import TokenManager
from utils.utils import (
    load_credentials,
    check_sheet_exists,
    update_task_scan_fields,
    update_task_process_fields,
    update_task_update_fields,
    batch_get,
    batch_update,
)

class SheetsInfoScanner:
    def __init__(self, conn, token_map, doc_id_map):
        self.conn = conn
        self.token_map = token_map  # –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –∏–∑ main.py
        self.doc_id_map = doc_id_map
        self.log_file = SHEETSINFO_LOG
        self.tasks = []

    def run(self):
        manager = TokenManager(self.token_map)

        while True:
            try:
                
                if not is_scanner_enabled("sheets_scanner"):
                    log_to_file(self.log_file, "‚è∏ –°–∫–∞–Ω–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω (sheets_scanner). –û–∂–∏–¥–∞–Ω–∏–µ...")
                    time.sleep(10)
                    continue
                
                log_section("‚ñ∂Ô∏è SheetsInfo –ê–∫—Ç–∏–≤–µ–Ω. –ù–æ–≤—ã–π —Ü–∏–∫–ª —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è", self.log_file)

                try:
                    # üîÅ –í—ã–±–æ—Ä —Ç–æ–∫–µ–Ω–∞ –∫–∞–∂–¥—ã–π —Ü–∏–∫–ª
                    self.token_name, token_path = manager.select_best_token(self.log_file)
                    log_to_file(self.log_file, f"üîë –í—ã–±—Ä–∞–Ω{self.token_name}")
                    self.service = load_credentials(token_path, self.log_file)
                    log_to_file(self.log_file, f"üîê –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–∫–µ–Ω: {self.token_name}")
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —Ç–æ–∫–µ–Ω–∞: {e}")
                    time.sleep(10)
                    continue

                try:
                    self.load_tasks()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–¥–∞—á: {e}")
                    raise

                try:
                    self.scan_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
                    raise

                try:
                    self.process_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                    raise

                try:
                    self.update_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
                    raise
                
                log_section(f"üîÑ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω. –°–ª–µ–¥—É—é—â–µ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ {SHEETINFO_INTERVAL} —Å–µ–∫—É–Ω–¥", self.log_file,)
                log_to_file(self.log_file, "")
                log_to_file(self.log_file, "")
                log_to_file(self.log_file, "")
                log_to_file(self.log_file, "")
                log_to_file(self.log_file, "")
                time.sleep(SHEETINFO_INTERVAL)

            except Exception as e:
                log_separator(self.log_file)
                log_to_file(self.log_file, f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                time.sleep(10)

#############################################################################################
# –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ –ë–î
#############################################################################################

    def load_tasks(self):
        # log_section("üß© üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ SheetsInfo", self.log_file)
        self.tasks = load_sheetsinfo_tasks(self.conn, self.log_file)

        if not self.tasks:
            log_section("‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ SheetsInfo.", self.log_file)
            return

        # log_section(f"üîÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.tasks)} –∑–∞–¥–∞—á.", self.log_file)
        for task in self.tasks:
            task.assign_doc_ids(self.doc_id_map)

#############################################################################################
# –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
#############################################################################################

    def scan_phase(self):
        log_section("üîç –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è", self.log_file)

        if not self.tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return

        ready_tasks = [task for task in self.tasks if task.is_ready_to_scan()]
        if not ready_tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.")
            return

        # log_to_file(self.log_file, f"üîé –ù–∞–π–¥–µ–Ω–æ {len(ready_tasks)} –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é:")

        scan_groups = defaultdict(list)
        for task in ready_tasks:
            if not task.assign_doc_ids(self.doc_id_map):
                log_to_file(self.log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å doc_id. –ü—Ä–æ–ø—É—Å–∫.")
                continue
            scan_groups[task.scan_group].append(task)

        for scan_group, group_tasks in scan_groups.items():
            # log_separator(self.log_file)
            # log_to_file(self.log_file, f"üìò –û–±—Ä–∞–±–æ—Ç–∫–∞ scan_group: {scan_group} ({len(group_tasks)} –∑–∞–¥–∞—á)")

            if not group_tasks:
                log_to_file(self.log_file, "‚ö™ –í –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∑–∞–¥–∞—á.")
                continue

            doc_id = group_tasks[0].source_doc_id
            unique_sheet_names = set(task.source_page_name for task in group_tasks)
            # log_to_file(self.log_file, f"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–∏—Å—Ç–æ–≤: {unique_sheet_names}")

            exists_map = {
                sheet_name: check_sheet_exists(self.service, doc_id, sheet_name, self.log_file, self.token_name)
                for sheet_name in unique_sheet_names
            }

            # for sheet_name, exists in exists_map.items():
            #     log_to_file(self.log_file, f"{'‚úÖ' if exists else '‚ö†Ô∏è'} –õ–∏—Å—Ç '{sheet_name}' {'—Å—É—â–µ—Å—Ç–≤—É–µ—Ç' if exists else '–Ω–µ –Ω–∞–π–¥–µ–Ω'}.")

            valid_tasks = []
            for task in group_tasks:
                sheet_name = task.source_page_name
                if exists_map.get(sheet_name):
                    # log_to_file(self.log_file, f"‚û°Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º '{sheet_name}' –¥–ª—è –∑–∞–¥–∞—á–∏ {task.name_of_process}.")
                    valid_tasks.append(task)
                else:
                    log_to_file(self.log_file, f"‚õî –ü—Ä–æ–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ {task.name_of_process}: –ª–∏—Å—Ç '{sheet_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                    task.update_after_scan(success=False)
                    update_task_scan_fields(self.conn, task, self.log_file, table_name="SheetsInfo")


            # if not valid_tasks:
            #     log_to_file(self.log_file, f"‚ö™ –í—Å–µ –∑–∞–¥–∞—á–∏ –≥—Ä—É–ø–ø—ã {scan_group} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ batchGet.")
            #     continue

            range_to_tasks = defaultdict(list)
            for task in valid_tasks:
                range_str = f"{task.source_page_name}!{task.source_page_area}"
                range_to_tasks[range_str].append(task)

            ranges = list(range_to_tasks.keys())

            # log_to_file(self.log_file, "")
            # log_to_file(self.log_file, f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ batchGet –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç {task.source_table_type} —Å {len(ranges)} —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏:")
            
            # for r in ranges:
            #     log_to_file(self.log_file, f"   ‚Ä¢ {r}")

            response_data = batch_get(self.service, 
                                      doc_id, 
                                      ranges, 
                                      scan_group, 
                                      self.log_file,
                                      self.token_name)
            if not response_data:
                # log_to_file(self.log_file, "‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç batchGet. –í—Å–µ –∑–∞–¥–∞—á–∏ –±—É–¥—É—Ç –æ—Ç–º–µ—á–µ–Ω—ã –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—ã–µ.")
                for task in valid_tasks:
                    task.update_after_scan(success=False) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ö–ª–∞—Å—Å–µ
                    update_task_scan_fields(self.conn, task, self.log_file, table_name="SheetsInfo") #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                continue

            normalized_response = {}
            for k, v in response_data.items():
                clean_key = k.replace("'", "")
                if "!" in clean_key:
                    sheet_name, cells_range = clean_key.split("!", 1)
                    normalized_response[(sheet_name.strip(), cells_range.strip())] = v

            # log_to_file(self.log_file, "")
            # log_to_file(self.log_file, f"üì• –ü–æ–ª—É—á–µ–Ω—ã –¥–∏–∞–ø–∞–∑–æ–Ω—ã: {list(normalized_response.keys())}")

            for task in valid_tasks:
                expected_sheet = task.source_page_name.strip()
                expected_area_start = task.source_page_area.split(":")[0].strip()
                matched_values = None
                
                for (sheet_name, cells_range), values in normalized_response.items():
                    if sheet_name == expected_sheet and cells_range.startswith(expected_area_start):
                        matched_values = values
                        break

                if matched_values:
                    task.raw_values_json = matched_values #–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ raw_values_json
                    task.update_after_scan(success=True) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ö–ª–∞—Å—Å–µ
                    update_task_scan_fields(self.conn, task, self.log_file, table_name="SheetsInfo") #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                    # log_to_file(self.log_file, f"‚úÖ [Task {task.name_of_process}] –ù–∞–π–¥–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω {sheet_name}!{cells_range}, —Å—Ç—Ä–æ–∫: {len(matched_values)}")
                else:
                    task.update_after_scan(success=False)
                    update_task_scan_fields(self.conn, task, self.log_file, table_name="SheetsInfo")
                    # log_to_file(self.log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –î–∏–∞–ø–∞–∑–æ–Ω {expected_sheet}!{task.source_page_area} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç.")
        for task in self.tasks:
            log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {task.scanned} | –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.proceed} | –ò–∑–º–µ–Ω–µ–Ω–æ: {task.changed} | –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {task.uploaded}")

#############################################################################################
# –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
#############################################################################################

    def process_phase(self):
        log_section("üõ†Ô∏è –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏", self.log_file)

        if not self.tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            return

        for task in self.tasks:
            if task.scanned == 0:
                continue
            try:
                # log_to_file(self.log_file, f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ [Task {task.name_of_process}]...")

                try:
                    task.process_raw_value() # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ values_json
                    
                    # log_to_file(self.log_file, f"üì¶ [Task {task.name_of_process}] –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(task.values_json)} —Å—Ç—Ä–æ–∫.")
                    # for i, row in enumerate(task.values_json[:5]):
                    #     log_to_file(self.log_file, f"      [{i+1}] {row}")
                    # if len(task.values_json) > 5:
                    #     log_to_file(self.log_file, f"      ...–µ—â—ë {len(task.values_json) - 5} —Å—Ç—Ä–æ–∫ —Å–∫—Ä—ã—Ç–æ")
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –≤ process_raw_value: {e}")
                    continue

                try:
                    task.check_for_update()

                    if task.changed:
                        # log_to_file(self.log_file, "üîÅ –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã ‚Äî –∑–∞–¥–∞—á–∞ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")
                        update_task_process_fields(self.conn, task, self.log_file, table_name="SheetsInfo")
                        # log_to_file(self.log_file, f"‚úÖ [Task {task.name_of_process}] –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ –ë–î.\n")
                    # else:
                    #     log_to_file(self.log_file, "‚ö™ –ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n")
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –≤ check_for_update: {e}")
                    continue

            except Exception as e:
                log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")


        for task in self.tasks:
            log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {task.scanned} | –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.proceed} | –ò–∑–º–µ–Ω–µ–Ω–æ: {task.changed} | –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {task.uploaded}")

#############################################################################################
# –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
#############################################################################################

    def update_phase(self):
        log_section("üîº –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è", self.log_file)
        # return  # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        
        has_tasks_changes = any(task.changed for task in self.tasks if task.update_group != "update_mistakes_in_db" and task.update_group != "feedback_status_update")
        log_to_file(self.log_file, f"üîº –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∑–∞–¥–∞—á–∞—Ö: {has_tasks_changes}")
        tasks_to_update = [task for task in self.tasks if task.values_json and task.update_group != "update_mistakes_in_db" and task.update_group != "feedback_status_update" and has_tasks_changes]
        log_to_file(self.log_file, f"üîº –ó–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(tasks_to_update)}")


        has_mistakes_changes = any(task.changed for task in self.tasks if task.update_group == "update_mistakes_in_db")
        log_to_file(self.log_file, f"üîº –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –æ—à–∏–±–∫–∞—Ö: {has_mistakes_changes}")
        mistakes_to_update = [task for task in self.tasks if task.values_json and task.update_group == "update_mistakes_in_db" and has_mistakes_changes]
        log_to_file(self.log_file, f"üîº –û—à–∏–±–æ–∫ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(mistakes_to_update)}")


        has_feedback_changes = any(task.changed for task in self.tasks if task.update_group == "feedback_status_update")
        log_to_file(self.log_file, f"üîº –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ñ–∏–¥–±–µ–∫–∞—Ö: {has_feedback_changes}")
        feedback_to_update = [task for task in self.tasks if task.values_json and task.update_group == "feedback_status_update" and has_feedback_changes]
        log_to_file(self.log_file, f"üîº –§–∏–¥–±–µ–∫–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(feedback_to_update)}")

        if tasks_to_update:
            try:
                self.import_tasks_to_update(tasks_to_update)
                # log_section("üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ tasks_to_update –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", self.log_file)
            except Exception as e:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ tasks_to_update: {e}")

        time.sleep(5)

        if mistakes_to_update:
            try:
                self.import_mistakes_to_update(mistakes_to_update)
                # log_section("üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ mistakes_to_update –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", self.log_file)
            except Exception as e:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ mistakes_to_update: {e}")
                
        time.sleep(5)

        if feedback_to_update:
            # –ü–æ–ª—É—á–∞–µ–º ID —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–∏–¥–±–µ–∫–æ–≤
            try:
                self.import_feedbacks_to_update(feedback_to_update, self.service)
                # log_section("üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ feedback_to_update –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", self.log_file)
            except Exception as e:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ feedback_to_update: {e}")

        for task in self.tasks:
            log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {task.scanned} | –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.proceed} | –ò–∑–º–µ–Ω–µ–Ω–æ: {task.changed} | –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {task.uploaded}")

        if not tasks_to_update and not mistakes_to_update and not feedback_to_update:
            # log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è. –ü—Ä–æ–ø—É—Å–∫.")
            return
        else:
            log_section("üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", self.log_file)

##############################################################################################
# –ò–º–ø–æ—Ä—Ç –û–±—ã—á–Ω—ã—Ö –∑–∞–¥–∞—á 
##############################################################################################

    def import_tasks_to_update(self, tasks_to_update):

        # log_to_file(self.log_file, f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã tasks_to_update. –ó–∞–¥–∞—á –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏: {len(tasks_to_update)}.")

        tasks_by_update_group = defaultdict(list)
        for task in tasks_to_update:
            tasks_by_update_group[task.update_group].append(task)

        for update_group, group_tasks in tasks_by_update_group.items():
            # log_section(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {update_group} ({len(group_tasks)} –∑–∞–¥–∞—á).", self.log_file)

            doc_id = group_tasks[0].target_doc_id

            batch_data = []
            for task in group_tasks:
                if not task.values_json:
                    log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏, –ø—Ä–æ–ø—É—Å–∫.")
                    continue

                batch_data.append({
                    "range": f"{task.target_page_name}!{task.target_page_area}",
                    "values": task.values_json
                })

            if not batch_data:
                log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è batchUpdate –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ.")
                continue

            success, error = batch_update(
                service=self.service,
                spreadsheet_id=doc_id,
                batch_data=batch_data,
                token_name=self.token_name,
                update_group=update_group,
                log_file=self.log_file
            )

            if success:
                for task in group_tasks:
                    task.update_after_upload(success=True)
                    update_task_update_fields(
                        conn=self.conn,
                        task=task,
                        log_file=self.log_file,
                        table_name="SheetsInfo"
                    )
                    insert_usage(
                        token=SHEETSINFO_TOKEN,
                        count=1,
                        scan_group=update_group,
                        success=True
                    )
                # log_to_file(self.log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã {update_group} ({len(group_tasks)} –∑–∞–¥–∞—á).")
            else:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ batchUpdate: {error}")
                log_to_file(self.log_file, "üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ—Ç–ø—Ä–∞–≤–∫—É –∑–∞–¥–∞—á.")

                for task in group_tasks:
                    if not task.values_json:
                        continue

                    single_data = [{
                        "range": f"{task.target_page_name}!{task.target_page_area}",
                        "values": task.values_json
                    }]
                    single_success, single_error = batch_update(
                        service=self.service,
                        spreadsheet_id=doc_id,
                        batch_data=single_data,
                        token_name=self.token_name,
                        update_group=update_group,
                        log_file=self.log_file
                    )                    

                    insert_usage(
                        token=SHEETSINFO_TOKEN,
                        count=1,
                        scan_group=update_group,
                        success=single_success
                    )

                    if single_success:
                        task.update_after_upload(success=True)
                        # log_to_file(self.log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ [Task {task.name_of_process}] –æ—Ç–¥–µ–ª—å–Ω–æ.")
                        # log_separator(self.log_file)
                        # log_to_file(self.log_file, "" * 100)
                    else:
                        task.update_after_upload(success=False)
                        log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è [Task {task.name_of_process}] –æ—Ç–¥–µ–ª—å–Ω–æ: {single_error}")
                        log_separator(self.log_file)
                        log_to_file(self.log_file, "" * 100)

                    update_task_update_fields(
                        conn=self.conn,
                        task=task,
                        log_file=self.log_file,
                        table_name="SheetsInfo"
                    )

                    # log_to_file(self.log_file, f"üíæ –û–±–Ω–æ–≤–ª—ë–Ω values_json –∏ hash –¥–ª—è –∑–∞–¥–∞—á–∏ {task.name_of_process}")

###############################################################################################
# –ò–º–ø–æ—Ä—Ç –û—à–∏–±–æ–∫ –≤ –ë–î
###############################################################################################

    @staticmethod
    def get_floor_by_table_name(table_name: str, floor_map: dict) -> str:
        for floor, tables in floor_map.items():
            if table_name in tables:
                return floor
        return "UNKNOWN"

    @staticmethod
    def get_max_last_row(conn, table_name):
        cursor = conn.cursor()
        cursor.execute("SELECT MAX(last_row) FROM MistakeStorage WHERE table_name = ?", (table_name,))
        result = cursor.fetchone()
        return result[0] if result and result[0] is not None else 0

    def import_mistakes_to_update(self, mistakes_to_update):
        log_to_file(self.log_file, f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã mistakes_to_update. –ó–∞–¥–∞—á –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏: {len(mistakes_to_update)}.")

        floor_list = {
            "VIP": ["vBJ2", "vBJ3", "gBC1", "vBC3", "vBC4", "vHSB1", "vDT1", "gsRL1", "swBC1", "swRL1"],
            "TURKISH": ["tBJ1", "tBJ2", "tRL1"],
            "GENERIC": ["gBJ1", "gBJ3", "gBJ4", "gBJ5", "gBC2", "gBC3", "gBC4", "gBC5", "gBC6", "gRL1", "gRL2"],
            "GSBJ": ["gsBJ1", "gsBJ2", "gsBJ3", "gsBJ4", "gsBJ5", "gRL3"],
            "LEGENDZ": ["lBJ1", "lBJ2", "lBJ3"]
        }

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        try:
            for task in mistakes_to_update:
                sheet = task.raw_values_json
                page_name = task.source_page_name
                floor = self.get_floor_by_table_name(page_name, floor_list)
                max_row_in_db = self.get_max_last_row(conn, page_name)

                for row_index, row in enumerate(sheet[1:], start=2):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    if row_index <= max_row_in_db:
                        continue

                    # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
                    if not row or len(row) < 8:
                        log_to_file(self.log_file, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ {row_index} –∏–∑ {page_name}: {row}")
                        continue

                    try:
                        is_cancel = 1 if str(row[5]).strip().lower() == "cancel" else 0

                        cursor.execute("""
                            INSERT INTO MistakeStorage (
                                floor, table_name, date, time, game_id, mistake, type,
                                is_cancel, dealer, sm, last_row
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            floor,
                            page_name,
                            row[0],  # date
                            row[1],  # time
                            row[2],  # game_id
                            row[3],  # mistake
                            row[4],  # type
                            is_cancel,
                            row[6],  # dealer
                            row[7],  # sm
                            row_index
                        ))

                    except Exception as row_err:
                        log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")
                        continue  # –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –µ–¥–µ–º –¥–∞–ª—å—à–µ

            conn.commit()
            log_to_file(self.log_file, "‚úÖ –í—Å–µ –æ—à–∏–±–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.")

        except Exception as task_err:
            log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ mistakes_to_update: {task_err}")

        finally:
            conn.close()
            log_to_file(self.log_file, "üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ñ–∞–∑—ã mistakes_to_update.")

################################################################################################
# –ò–º–ø–æ—Ä—Ç —Å—Ç–∞—Ç—É—Å–∞ —Ñ–∏–¥–±–µ–∫–æ–≤
################################################################################################

    def update_gp_statuses_in_sheet(self, sheets_service):

        for task in self.tasks:
            if task.update_group == "feedback_status_update":
                sheet_id = task.target_doc_id
                targer_page_name = task.target_page_name
                target_page_area = task.target_page_area
                range = f"{targer_page_name}!{target_page_area}"
                break
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –∏–º–µ–Ω–µ–º –∏ –ø—Ä–∏—á–∏–Ω–æ–π (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–µ, —É –∫–æ–≥–æ –ø—É—Å—Ç–æ–µ –∏–º—è)
            cursor.execute("""
                SELECT GP_Name_Surname, Reason, Forwarded_Feedback
                FROM FeedbackStorage
                WHERE GP_Name_Surname IS NOT NULL AND TRIM(GP_Name_Surname) != ''
            """)
            rows = cursor.fetchall()

            # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ –µ—Å—Ç—å –≤ –ë–î
            gp_status = {}

            for name, reason, forwarded in rows:
                if reason and reason.strip():
                    if forwarded and forwarded.strip():
                        gp_status[name] = "‚úÖ"
                    else:
                        gp_status[name] = "‚ùå"

            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–º–µ–Ω –∏–∑ Google Sheet
            result = sheets_service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range="Info!A1:A300"
            ).execute()

            sheet_names = [row[0].strip() for row in result.get("values", []) if row and row[0].strip()]

            # –°–æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ —Å—Ç–∞—Ç—É—Å–∞–º–∏
            output = []
            for name in sheet_names:
                status = gp_status.get(name, "...")
                output.append([name, status])
                # print(f"–ò–º—è: {name}, –°—Ç–∞—Ç—É—Å: {status}")

            # –û–±–Ω–æ–≤–ª—è–µ–º Google Sheet
            sheets_service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range=range,
                valueInputOption="RAW",
                body={"values": output}
            ).execute()

            # log_to_file(self.log_file, f"üìã –û–±–Ω–æ–≤–ª–µ–Ω—ã —Å—Ç–∞—Ç—É—Å—ã GP –≤ Info!A1:B300: {len(output)} –∑–∞–ø–∏—Å–µ–π.")
            return output

        except Exception as e:
            log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ GP —Å—Ç–∞—Ç—É—Å–æ–≤: {e}")
            return []

        finally:
            conn.close()

    def import_feedbacks_to_update(self, feedback_to_update, sheets_service):
        # log_to_file(self.log_file, f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã feedback_status_update. –ó–∞–¥–∞—á –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏: {len(feedback_to_update)}.")

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        try:
            for task in feedback_to_update:
                sheet = task.raw_values_json
                page_name = task.target_page_name
                empty_row_streak = 0  # —Å—á—ë—Ç—á–∏–∫ –ø–æ–¥—Ä—è–¥ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫

                for row_index, row in enumerate(sheet[1:], start=2):
                    if not row or not row[0].isdigit():
                        # log_to_file(self.log_file, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row_index} –∏–∑ {page_name} (–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π id): {row}")
                        continue

                    feedback_id = int(row[0])
                    data = row[1:]

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫–∏ –¥–æ 13 –ø–æ–ª–µ–π
                    expected_len = 13
                    if len(data) < expected_len:
                        data += [None] * (expected_len - len(data))
                    elif len(data) > expected_len:
                        data = data[:expected_len]

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –≤—Å–µ –ª–∏ –ø–æ–ª—è (–∫—Ä–æ–º–µ Proof, —Ç.–µ. data[8]) –∏ id ‚Äî –ø—É—Å—Ç—ã?
                    essential_fields = data[:8] + data[9:]  # –∏—Å–∫–ª—é—á–∞–µ–º Proof (data[8])
                    if all((str(f or '').strip() == '') for f in essential_fields):
                        empty_row_streak += 1
                    else:
                        empty_row_streak = 0  # —Å–±—Ä–æ—Å —Å—á—ë—Ç—á–∏–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ

                    # –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É, –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ 5 –ø–æ–¥—Ä—è–¥ "–ø—É—Å—Ç—ã—Ö" —Å—Ç—Ä–æ–∫
                    if empty_row_streak >= 15:
                        # log_to_file(self.log_file, f"‚èπÔ∏è –ò–º–ø–æ—Ä—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ—Å–ª–µ {empty_row_streak} –ø–æ–¥—Ä—è–¥ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ (—Å—Ç—Ä–æ–∫–∞ {row_index})")
                        break

                    try:
                        cursor.execute("SELECT id FROM FeedbackStorage WHERE id = ?", (feedback_id,))
                        exists = cursor.fetchone()

                        if exists:
                            cursor.execute("""
                                UPDATE FeedbackStorage SET
                                    Date = ?, Shift = ?, Floor = ?, Game = ?, GP_Name_Surname = ?,
                                    SM_Name_Surname = ?, Reason = ?, Total = ?, Proof = ?,
                                    Explanation_of_the_reason = ?, Action_taken = ?, Forwarded_Feedback = ?, Comment_after_forwarding = ?
                                WHERE id = ?
                            """, (*data, feedback_id))
                            # log_to_file(self.log_file, f"üîÑ –û–±–Ω–æ–≤–ª—ë–Ω —Ñ–∏–¥–±–µ–∫ id={feedback_id} –∏–∑ {page_name}")
                        else:
                            cursor.execute("""
                                INSERT INTO FeedbackStorage (
                                    id, Date, Shift, Floor, Game, GP_Name_Surname,
                                    SM_Name_Surname, Reason, Total, Proof,
                                    Explanation_of_the_reason, Action_taken,
                                    Forwarded_Feedback, Comment_after_forwarding
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, (feedback_id, *data))
                            # log_to_file(self.log_file, f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω —Ñ–∏–¥–±–µ–∫ id={feedback_id} –∏–∑ {page_name}")

                    except Exception as row_err:
                        log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")

            conn.commit()
            # log_to_file(self.log_file, "‚úÖ –í—Å–µ —Ñ–∏–¥–±–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.")
        except Exception as e:
            log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ —Ñ–∏–¥–±–µ–∫–æ–≤: {e}")
        finally:
            conn.close()
            # log_to_file(self.log_file, "üîÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–¥–±–µ–∫–æ–≤ –≤ –ë–î")
            self.update_gp_statuses_in_sheet(sheets_service)
            log_to_file(self.log_file, "üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ñ–∞–∑—ã feedback_status_update.")
