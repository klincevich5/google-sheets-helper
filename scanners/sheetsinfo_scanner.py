# scanners/sheetsinfo_scanner.py

import time
from datetime import datetime, timedelta
from collections import defaultdict

from tg_bot.utils.settings_access import is_scanner_enabled
from core.data import load_sheetsinfo_tasks
from utils.logger import (
    log_info, log_success, log_warning, log_error, log_section, log_separator
)
from utils.db_orm import get_max_last_row
from utils.floor_resolver import get_floor_by_table_name
from database.session import SessionLocal

from database.db_models import MistakeStorage, FeedbackStorage,  ScheduleOT, DealerMonthlyStatus, QaList

from core.config import (
    SHEETSINFO_LOG,
    SHEETINFO_INTERVAL,
    FLOORS
)
from utils.db_orm import (
    update_task_scan_fields,
    update_task_process_fields,
    update_task_update_fields
)
from utils.utils import (
    load_credentials,
    check_sheet_exists,
    batch_get,
    batch_update,
)

class SheetsInfoScanner:
    """
    SheetsInfoScanner ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á –ø–æ Google Sheets.
    """

    def __init__(self, token_map, doc_id_map):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–∞–Ω–µ—Ä–∞.
        :param token_map: —Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è Google Sheets API
        :param doc_id_map: —Å–ª–æ–≤–∞—Ä—å doc_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∞–±–ª–∏—Ü
        """
        self.token_map = token_map
        self.doc_id_map = doc_id_map
        self.log_file = SHEETSINFO_LOG
        self.tasks = []

    def run(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã —Å–∫–∞–Ω–µ—Ä–∞: –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á, —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ–±—Ä–∞–±–æ—Ç–∫–∞, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.
        """
        while True:
            try:
                if not is_scanner_enabled("sheets_scanner"):
                    time.sleep(10)
                    continue

                log_separator(self.log_file, "run")
                log_section(self.log_file, "run", "‚ñ∂Ô∏è SheetsInfo –ê–∫—Ç–∏–≤–µ–Ω. –ù–æ–≤—ã–π —Ü–∏–∫–ª —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n")

                token_name = list(self.token_map.keys())[0]
                token_path = self.token_map[token_name]
                self.token_name = token_name

                with SessionLocal() as session:
                    self.service = load_credentials(token_path, self.log_file)
                    log_info(self.log_file, "run", None, "token", f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–∫–µ–Ω: {self.token_name}")

                    for phase_name, method in [
                        ("load_tasks", lambda: self.load_tasks(session)),
                        ("scan_phase", lambda: self.scan_phase(session)),
                        ("process_phase", lambda: self.process_phase(session)),
                        ("update_phase", lambda: self.update_phase(session)),
                    ]:
                        log_separator(self.log_file, phase_name)
                        try:
                            log_info(self.log_file, phase_name, None, "start", f"–°—Ç–∞—Ä—Ç —ç—Ç–∞–ø–∞ {phase_name}")
                            method()
                            log_success(self.log_file, phase_name, None, "finish", f"–≠—Ç–∞–ø {phase_name} –∑–∞–≤–µ—Ä—à—ë–Ω\n")
                        except Exception as e:
                            log_error(self.log_file, phase_name, None, "fail", "–û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ", exc=e)
                            raise

            except Exception as e:
                log_error(self.log_file, "run", None, "fail", "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ", exc=e)
                time.sleep(10)

            time.sleep(SHEETINFO_INTERVAL)

    def _validate_sheet(self, sheet):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ sheet ‚Äî —ç—Ç–æ –Ω–µ–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.
        """
        return sheet and isinstance(sheet, list)

    def _commit_or_rollback(self, session, log_msg=None):
        """
        –ö–æ–º–º–∏—Ç–∏—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏–ª–∏ –¥–µ–ª–∞–µ—Ç rollback –ø—Ä–∏ –æ—à–∏–±–∫–µ.
        """
        try:
            session.commit()
        except Exception as e:
            session.rollback()
            if log_msg:
                log_error(self.log_file, "SheetsInfoScanner", "_commit_or_rollback", None, "commit_fail", f"{log_msg}: {e}")

    def _is_valid_qa_row(self, row):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ QA List –≤–∞–ª–∏–¥–Ω–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ë–î.
        """
        # –ú–∏–Ω–∏–º—É–º dealer_name –∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω TRUE/FALSE –≤ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª—è—Ö
        if not row or len(row) < 18:
            return False
        if not row[0] or not isinstance(row[0], str):
            return False
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –ø–æ–ª—è–º
        return True

#############################################################################################
# –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ –ë–î
#############################################################################################

    def load_tasks(self, session):
        log_section(self.log_file, "load_tasks", "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ SheetsInfo")
        self.tasks = load_sheetsinfo_tasks(session, self.log_file)
        if not self.tasks:
            log_info(self.log_file, "load_tasks", None, "empty", "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
            self.tasks = []
            return
        skipped = 0
        for task in self.tasks:
            if not task.assign_doc_ids(self.doc_id_map):
                skipped += 1
                log_warning(self.log_file, "load_tasks", getattr(task, 'name_of_process', None), "skipped", "–ù–µ—Ç doc_id, –∑–∞–¥–∞—á–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞")
        log_info(self.log_file, "load_tasks", None, "done", f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–¥–∞—á: {len(self.tasks)}, –ø—Ä–æ–ø—É—â–µ–Ω–æ –±–µ–∑ doc_id: {skipped}")

#############################################################################################
# –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
#############################################################################################

    def scan_phase(self, session):
        log_section(self.log_file, "scan_phase", "üîç –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
        if not self.tasks:
            log_info(self.log_file, "scan_phase", None, "empty", "–ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        ready_tasks = [task for task in self.tasks if task.is_ready_to_scan()]
        log_info(self.log_file, "scan_phase", None, "ready", f"–ì–æ—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á: {len(ready_tasks)}")
        if not ready_tasks:
            log_info(self.log_file, "scan_phase", None, "empty", "–ù–µ—Ç –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é")
            return
        scan_groups = defaultdict(list)
        for task in ready_tasks:
            if not task.assign_doc_ids(self.doc_id_map):
                log_warning(self.log_file, "scan_phase", getattr(task, 'name_of_process', None), "skipped", "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å doc_id. –ü—Ä–æ–ø—É—Å–∫.")
                continue
            scan_groups[task.scan_group].append(task)
        for scan_group, group_tasks in scan_groups.items():
            log_section(self.log_file, "scan_phase", f"\nüóÇÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ scan_group: {scan_group} ({len(group_tasks)} –∑–∞–¥–∞—á)\n")
            if not group_tasks:
                continue
            doc_id = group_tasks[0].source_doc_id
            unique_sheet_names = set(task.source_page_name for task in group_tasks)
            exists_map = {
                sheet_name: check_sheet_exists(self.service, doc_id, sheet_name, self.log_file, self.token_name)
                for sheet_name in unique_sheet_names
            }
            for sheet_name, exists in exists_map.items():
                log_info(self.log_file, "scan_phase", None, "sheet_exists", f"–õ–∏—Å—Ç '{sheet_name}' {'—Å—É—â–µ—Å—Ç–≤—É–µ—Ç' if exists else '–Ω–µ –Ω–∞–π–¥–µ–Ω'}")
            valid_tasks = []
            for task in group_tasks:
                sheet_name = task.source_page_name
                if exists_map.get(sheet_name):
                    valid_tasks.append(task)
                else:
                    log_warning(self.log_file, "scan_phase", task.name_of_process, "skipped", f"–õ–∏—Å—Ç '{sheet_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    task.update_after_scan(success=False)
                    update_task_scan_fields(session, task, self.log_file, table_name="SheetsInfo")
            if not valid_tasks:
                log_info(self.log_file, "scan_phase", None, "empty", f"–í—Å–µ –∑–∞–¥–∞—á–∏ –≥—Ä—É–ø–ø—ã {scan_group} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ batchGet.")
                continue
            range_to_tasks = defaultdict(list)
            for task in valid_tasks:
                range_str = f"{task.source_page_name}!{task.source_page_area}"
                range_to_tasks[range_str].append(task)
            ranges = list(range_to_tasks.keys())
            log_info(self.log_file, "scan_phase", None, "batch_get", f"–û—Ç–ø—Ä–∞–≤–∫–∞ batchGet –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç {task.source_table_type} —Å {len(ranges)} –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏")
            response_data = batch_get(
                self.service,
                doc_id,
                ranges,
                scan_group,
                self.log_file,
                self.token_name
            )
            if not response_data:
                for task in valid_tasks:
                    task.update_after_scan(success=False)
                    update_task_scan_fields(session, task, self.log_file, table_name="SheetsInfo")
                log_warning(self.log_file, "scan_phase", None, "empty", "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç batchGet. –í—Å–µ –∑–∞–¥–∞—á–∏ –±—É–¥—É—Ç –æ—Ç–º–µ—á–µ–Ω—ã –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—ã–µ.")
                continue
            normalized_response = {}
            for k, v in response_data.items():
                clean_key = k.replace("'", "")
                if "!" in clean_key:
                    sheet_name, cells_range = clean_key.split("!", 1)
                    normalized_response[(sheet_name.strip(), cells_range.strip())] = v
            for task in valid_tasks:
                expected_sheet = task.source_page_name.strip()
                expected_area_start = task.source_page_area.split(":")[0].strip()
                matched_values = None
                for (sheet_name, cells_range), values in normalized_response.items():
                    if sheet_name == expected_sheet and cells_range.startswith(expected_area_start):
                        matched_values = values
                        break
                if matched_values:
                    task.raw_values_json = matched_values
                    task.update_after_scan(success=True)
                    update_task_scan_fields(session, task, self.log_file, table_name="SheetsInfo")
                    log_success(self.log_file, "scan_phase", task.name_of_process, "found", f"–ù–∞–π–¥–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω {sheet_name}!{cells_range}, —Å—Ç—Ä–æ–∫: {len(matched_values)}")
                else:
                    task.update_after_scan(success=False)
                    update_task_scan_fields(session, task, self.log_file, table_name="SheetsInfo")
                    log_warning(self.log_file, "scan_phase", task.name_of_process, "not_found", f"–î–∏–∞–ø–∞–∑–æ–Ω {expected_sheet}!{task.source_page_area} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç.")
        log_info(self.log_file, "scan_phase", None, "summary", "\n".join(
            [f"‚Ä¢ {task.name_of_process} {task.source_page_name}: scanned={task.scanned}, processed={task.proceed}, changed={task.changed}, uploaded={task.uploaded}"
             for task in self.tasks]
        ) + "\n")
        log_success(self.log_file, "scan_phase", None, "finish", "–§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n")

#############################################################################################
# –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
#############################################################################################

    def process_phase(self, session):
        log_section(self.log_file, "process_phase", "üõ†Ô∏è –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        if not self.tasks:
            log_info(self.log_file, "process_phase", None, "empty", "–ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        for task in self.tasks:
            if task.scanned == 0:
                continue
            try:
                try:
                    task.process_raw_value()
                except Exception as e:
                    log_error(self.log_file, "process_phase", task.name_of_process, "fail", "–û—à–∏–±–∫–∞ –≤ process_raw_value", exc=e)
                    continue
                try:
                    task.check_for_update()
                except Exception as e:
                    log_error(self.log_file, "process_phase", task.name_of_process, "fail", "–û—à–∏–±–∫–∞ –≤ check_for_update", exc=e)
                    continue
                if task.changed:
                    try:
                        update_task_process_fields(session, task, self.log_file, table_name="SheetsInfo")
                        log_success(self.log_file, "process_phase", task.name_of_process, "changed", "–î–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
                    except Exception as e:
                        log_error(self.log_file, "process_phase", task.name_of_process, "fail", "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ë–î", exc=e)
            except Exception as e:
                log_error(self.log_file, "process_phase", task.name_of_process, "fail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ", exc=e)
        log_info(self.log_file, "process_phase", None, "summary", "\n".join(
            [f"‚Ä¢ {task.name_of_process} {task.source_page_name}: scanned={task.scanned}, processed={task.proceed}, changed={task.changed}, uploaded={task.uploaded}"
             for task in self.tasks]
        ) + "\n")
        log_success(self.log_file, "process_phase", None, "finish", "–§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n")

#############################################################################################
# –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
#############################################################################################

    def update_phase(self, session):
        log_section(self.log_file, "update_phase", "üîº –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
        # --- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á ---
        tasks_to_update = []
        mistakes_to_update = []
        feedback_to_update = []
        schedule_OT_to_update = []
        qa_list_update = []

        for t in self.tasks:
            if not (t.values_json and t.changed):
                continue
            if t.update_group == "update_mistakes_in_db":
                mistakes_to_update.append(t)
            elif t.update_group == "feedback_status_update":
                feedback_to_update.append(t)
            elif t.update_group == "update_schedule_OT":
                schedule_OT_to_update.append(t)
            elif t.update_group == "update_qa_list_db":
                qa_list_update.append(t)
            else:
                tasks_to_update.append(t)

        # --- –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π ---
        log_info(self.log_file, "update_phase", None, "tasks_to_update", f"üîº –ó–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(tasks_to_update)}")
        for task in tasks_to_update:
            log_info(self.log_file, "update_phase", task.name_of_process, "tasks_to_update", f"   ‚Ä¢ {task.name_of_process} ({task.update_group})")
        log_info(self.log_file, "update_phase", None, "mistakes_to_update", f"üîº –û—à–∏–±–æ–∫ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(mistakes_to_update)}")
        for task in mistakes_to_update:
            log_info(self.log_file, "update_phase", task.name_of_process, "mistakes_to_update", f"   ‚Ä¢ {task.name_of_process} ({task.update_group})")
        log_info(self.log_file, "update_phase", None, "feedback_to_update", f"üîº –§–∏–¥–±–µ–∫–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(feedback_to_update)}")
        for task in feedback_to_update:
            log_info(self.log_file, "update_phase", task.name_of_process, "feedback_to_update", f"   ‚Ä¢ {task.name_of_process} ({task.update_group})")
        log_info(self.log_file, "update_phase", None, "schedule_OT_to_update", f"üîº Schedule OT –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(schedule_OT_to_update)}")
        for task in schedule_OT_to_update:
            log_info(self.log_file, "update_phase", task.name_of_process, "schedule_OT_to_update", f"   ‚Ä¢ {task.name_of_process} ({task.update_group})")
        log_info(self.log_file, "update_phase", None, "qa_list_update", f"üîº QA List –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(qa_list_update)}")
        for task in qa_list_update:
            log_info(self.log_file, "update_phase", task.name_of_process, "qa_list_update", f"   ‚Ä¢ {task.name_of_process} ({task.update_group})")

        # --- –û–±—ã—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ ---
        if tasks_to_update:
            log_info(self.log_file, "update_phase", None, "tasks_to_update", f"üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—ã—á–Ω—ã—Ö –∑–∞–¥–∞—á: {len(tasks_to_update)}")
            try:
                self.import_tasks_to_update(tasks_to_update, session)
            except Exception as e:
                log_error(self.log_file, "update_phase", None, "tasks_to_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∑–∞–¥–∞—á: {e}")
            time.sleep(3)

        # --- –û—à–∏–±–∫–∏ ---
        if mistakes_to_update:
            log_info(self.log_file, "update_phase", None, "mistakes_to_update", f"üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫: {len(mistakes_to_update)}")
            try:
                self.import_mistakes_to_update(mistakes_to_update, session)
                for t in mistakes_to_update:
                    t.update_after_upload(success=True)
                    update_task_update_fields(session, t, self.log_file, table_name="SheetsInfo")
                session.commit()
            except Exception as e:
                session.rollback()
                log_error(self.log_file, "update_phase", None, "mistakes_to_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –æ—à–∏–±–æ–∫: {e}")
            time.sleep(3)

        # --- –§–∏–¥–±–µ–∫–∏ ---
        if feedback_to_update:
            log_info(self.log_file, "update_phase", None, "feedback_to_update", f"üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∏–¥–±–µ–∫–æ–≤: {len(feedback_to_update)}")
            try:
                self.import_feedbacks_to_update(feedback_to_update, self.service, session)
                for t in feedback_to_update:
                    t.update_after_upload(success=True)
                    update_task_update_fields(session, t, self.log_file, table_name="SheetsInfo")
                session.commit()
            except Exception as e:
                session.rollback()
                log_error(self.log_file, "update_phase", None, "feedback_to_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∏–¥–±–µ–∫–æ–≤: {e}")

        # --- Schedule OT ---
        if schedule_OT_to_update:
            log_info(self.log_file, "update_phase", None, "schedule_OT_to_update", f"üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ OT: {len(schedule_OT_to_update)}")
            try:
                self.import_schedule_OT_to_update(schedule_OT_to_update, session)
                for t in schedule_OT_to_update:
                    t.update_after_upload(success=True)
                    update_task_update_fields(session, t, self.log_file, table_name="SheetsInfo")
                session.commit()
            except Exception as e:
                session.rollback()
                log_error(self.log_file, "update_phase", None, "schedule_OT_to_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ schedule OT: {e}")
            time.sleep(3)

        # --- QA List ---
        if qa_list_update:
            log_info(self.log_file, "update_phase", None, "qa_list_update", f"üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ QA List: {len(qa_list_update)}")
            try:
                self.import_qa_list_to_update(qa_list_update, session)
                for t in qa_list_update:
                    t.update_after_upload(success=True)
                    update_task_update_fields(session, t, self.log_file, table_name="SheetsInfo")
                session.commit()
            except Exception as e:
                session.rollback()
                log_error(self.log_file, "update_phase", None, "qa_list_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ QA List: {e}")
            time.sleep(3)

        # --- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–¥–∞—á–∞–º ---
        log_info(self.log_file, "update_phase", None, "summary", "üîº –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–¥–∞—á–∞–º:")
        for task in self.tasks:
            log_info(
                self.log_file,
                "update_phase",
                task.name_of_process,
                "summary",
                f"‚ö™ [Task {task.name_of_process} {task.source_page_name} {task.related_month}] "
                f"–û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {task.scanned} | –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.proceed} | "
                f"–ò–∑–º–µ–Ω–µ–Ω–æ: {task.changed} | –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {task.uploaded}"
            )

        log_section(self.log_file, "update_phase", "üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n")

##############################################################################################
# –ò–º–ø–æ—Ä—Ç –û–±—ã—á–Ω—ã—Ö –∑–∞–¥–∞—á 
##############################################################################################

    def import_tasks_to_update(self, tasks_to_update, session):
        log_info(self.log_file, "import_tasks_to_update", None, "start", f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã tasks_to_update. –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(tasks_to_update)}")

        tasks_by_group = defaultdict(list)
        for task in tasks_to_update:
            tasks_by_group[task.update_group].append(task)

        for update_group, group_tasks in tasks_by_group.items():
            log_info(self.log_file, "import_tasks_to_update", None, "group", f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã: {update_group} ({len(group_tasks)} –∑–∞–¥–∞—á)")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ doc_id
            doc_ids = set(t.target_doc_id for t in group_tasks)
            if len(doc_ids) != 1:
                log_error(self.log_file, "import_tasks_to_update", None, "multi_doc_id", f"‚ùå –í –≥—Ä—É–ø–ø–µ {update_group} –Ω–µ—Å–∫–æ–ª—å–∫–æ doc_id: {doc_ids}. –ü—Ä–æ–ø—É—Å–∫.")
                continue
            doc_id = doc_ids.pop()

            batch_data = self._build_batch_data(group_tasks)
            if not batch_data:
                log_warning(self.log_file, "import_tasks_to_update", None, "no_data", f"‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è batchUpdate –≥—Ä—É–ø–ø—ã {update_group}. –ü—Ä–æ–ø—É—Å–∫.")
                continue

            try:
                success, error = batch_update(
                    service=self.service,
                    spreadsheet_id=doc_id,
                    batch_data=batch_data,
                    token_name=self.token_name,
                    update_group=update_group,
                    log_file=self.log_file
                )
                if success:
                    log_success(self.log_file, "import_tasks_to_update", None, "batch_update", f"‚úÖ –ü–∞–∫–µ—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –¥–ª—è –≥—Ä—É–ø–ø—ã {update_group}")
                    try:
                        self._mark_tasks_uploaded(group_tasks, session)
                        session.commit()
                    except Exception as db_err:
                        session.rollback()
                        log_error(self.log_file, "import_tasks_to_update", None, "db_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á –≤ –ë–î: {db_err}")
                else:
                    log_error(self.log_file, "import_tasks_to_update", None, "batch_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ: {error}")
                    self._fallback_single_upload(group_tasks, doc_id, update_group, session)
            except Exception as e:
                log_error(self.log_file, "import_tasks_to_update", None, "batch_update_exception", f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ batch_update: {e}")
                self._fallback_single_upload(group_tasks, doc_id, update_group, session)

    def _mark_tasks_uploaded(self, tasks, session):
        for task in tasks:
            try:
                task.update_after_upload(success=True)
                update_task_update_fields(
                    session=session,
                    task=task,
                    log_file=self.log_file,
                    table_name="SheetsInfo"
                )
            except Exception as e:
                log_error(self.log_file, "import_tasks_to_update", task.name_of_process, "db_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {e}")

    def _fallback_single_upload(self, tasks, doc_id, update_group, session):
        for task in tasks:
            if not task.values_json:
                continue

            single_data = [{
                "range": f"{task.target_page_name}!{task.target_page_area}",
                "values": task.values_json
            }]

            try:
                success, error = batch_update(
                    service=self.service,
                    spreadsheet_id=doc_id,
                    batch_data=single_data,
                    token_name=self.token_name,
                    update_group=update_group,
                    log_file=self.log_file
                )
                if success:
                    log_success(self.log_file, "import_tasks_to_update", task.name_of_process, "single_update", f"‚úÖ [Task {task.name_of_process} {task.source_page_name} {task.related_month}] –û–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—à—Ç—É—á–Ω–æ.")
                else:
                    log_error(self.log_file, "import_tasks_to_update", task.name_of_process, "single_update_fail", f"‚ùå [Task {task.name_of_process} {task.source_page_name} {task.related_month}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {error}")
                try:
                    task.update_after_upload(success=success)
                    update_task_update_fields(
                        session=session,
                        task=task,
                        log_file=self.log_file,
                        table_name="SheetsInfo"
                    )
                    session.commit()
                except Exception as db_err:
                    session.rollback()
                    log_error(self.log_file, "import_tasks_to_update", task.name_of_process, "db_update_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ {task.name_of_process} –≤ –ë–î: {db_err}")
            except Exception as e:
                log_error(self.log_file, "import_tasks_to_update", task.name_of_process, "single_update_exception", f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–æ—à—Ç—É—á–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {e}")

###############################################################################################
# –ò–º–ø–æ—Ä—Ç –û—à–∏–±–æ–∫ –≤ –ë–î
###############################################################################################

    def import_mistakes_to_update(self, mistakes_to_update, session):
        """
        –ò–º–ø–æ—Ä—Ç –æ—à–∏–±–æ–∫ –≤ –ë–î —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö.
        """
        total_success = 0
        total_error = 0

        for task in mistakes_to_update:
            success_count = 0
            error_count = 0
            try:
                sheet = task.raw_values_json
                if not self._validate_sheet(sheet):
                    log_warning(self.log_file, "import_mistakes_to_update", task.name_of_process, "empty_sheet", f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π sheet –≤ –∑–∞–¥–∞—á–µ: {task.name_of_process}")
                    continue

                page_name = task.source_page_name
                floor = get_floor_by_table_name(page_name, FLOORS)
                max_row_in_db = get_max_last_row(session, page_name)

                for row_index, row in enumerate(sheet[1:], start=2):
                    if row_index <= max_row_in_db or not row or len(row) < 8:
                        continue

                    exists = session.query(MistakeStorage).filter_by(
                        related_month=task.related_month,
                        table_name=page_name,
                        last_row=row_index
                    ).first()
                    if exists:
                        continue

                    try:
                        mistake = self._parse_mistake_row(task, row, row_index, floor, page_name)
                        if mistake:
                            session.add(mistake)
                            success_count += 1
                    except Exception as row_err:
                        log_error(self.log_file, "import_mistakes_to_update", task.name_of_process, "row_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")
                        error_count += 1

                self._commit_or_rollback(session, log_msg=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–º–∏—Ç–µ –æ—à–∏–±–æ–∫ –¥–ª—è {task.name_of_process}")
                log_success(self.log_file, "import_mistakes_to_update", task.name_of_process, "imported", f"‚úÖ [{task.name_of_process}] –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ—à–∏–±–æ–∫: {success_count}, –æ—à–∏–±–æ–∫: {error_count}")
                total_success += success_count
                total_error += error_count

            except Exception as task_err:
                session.rollback()
                log_error(self.log_file, "import_mistakes_to_update", task.name_of_process, "task_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {task_err}")

        log_success(self.log_file, "import_mistakes_to_update", None, "imported_total", f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ—à–∏–±–æ–∫ –≤—Å–µ–≥–æ: {total_success}, –æ—à–∏–±–æ–∫: {total_error}")

    def _parse_mistake_row(self, task, row, row_index, floor, page_name):
        date = self.parse_date(row[0])
        time_ = self.parse_time(row[1])
        shift = self.determine_shift(time_.hour) if time_ else None

        return MistakeStorage(
            related_month=task.related_month,
            related_date=date,
            related_shift=shift,
            floor=floor,
            table_name=page_name,
            event_time=time_,
            game_id=row[2],
            mistake=row[3],
            mistake_type=row[4],
            is_cancel=self.parse_cancel(row[5]),
            dealer_name=row[6],
            sm_name=row[7],
            last_row=row_index
        )


################################################################################################
# –ò–º–ø–æ—Ä—Ç —Å—Ç–∞—Ç—É—Å–∞ —Ñ–∏–¥–±–µ–∫–æ–≤
################################################################################################

    @staticmethod
    def safe_int(value):
        try:
            if value == '' or value is None:
                return None
            return int(value)
        except (ValueError, TypeError):
            return None

    @staticmethod
    def parse_cancel(value):
        if value == '':
            return 0
        elif value.lower() == 'cancel':
            return 1
        return None

    @staticmethod
    def parse_date(value):
        try:
            return datetime.strptime(value.strip(), "%d.%m.%Y").date()
        except Exception:
            return None
        
    @staticmethod
    def parse_time(value):
        try:
            return datetime.strptime(value.strip(), "%H.%M").time()
        except Exception:
            return None
        
    def _parse_feedback_row(self, row, task):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É feedback –≤ dict –¥–ª—è FeedbackStorage.
        –û–∂–∏–¥–∞–µ—Ç—Å—è –ø–æ—Ä—è–¥–æ–∫: [related_date, related_shift, floor, game, dealer_name, sm_name, reason, total, proof, explanation_of_the_reason, action_taken, forwarded_feedback, comment_after_forwarding]
        """
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ç—Ä–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ proof –∏–ª–∏ comment –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç)
        def safe(idx):
            return row[idx] if len(row) > idx and row[idx] != "" else None

        return {
            "related_date": self.parse_date(safe(0)),
            "related_shift": safe(1),
            "floor": safe(2),
            "game": safe(3),
            "dealer_name": safe(4),
            "sm_name": safe(5),
            "reason": safe(6),
            "total": self.safe_int(safe(7)),
            "proof": safe(8),
            "explanation_of_the_reason": safe(9),
            "action_taken": safe(10),
            "forwarded_feedback": safe(11),
            "comment_after_forwarding": safe(12),
        }

    def import_feedbacks_to_update(self, feedback_to_update, sheets_service, session):
        total_success = 0
        total_error = 0

        for task in feedback_to_update:
            success_count = 0
            error_count = 0
            try:
                sheet = task.raw_values_json
                if not sheet or not isinstance(sheet, list):
                    log_warning(self.log_file, "import_feedbacks_to_update", task.name_of_process, "empty_sheet", f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π sheet –≤ –∑–∞–¥–∞—á–µ: {task.name_of_process}")
                    continue

                page_name = task.target_page_name
                empty_row_streak = 0

                for row_index, row in enumerate(sheet[1:], start=2):  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    if not row or not str(row[0]).isdigit():
                        continue

                    feedback_id = int(row[0])
                    try:
                        parsed = self._parse_feedback_row(row[1:], task)
                        # –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ related_date –∏ related_shift –ø—É—Å—Ç—ã–µ
                        if not parsed["related_date"] and not parsed["related_shift"]:
                            continue
                        if parsed is None:
                            empty_row_streak += 1
                            if empty_row_streak >= 15:
                                break
                            continue
                        else:
                            empty_row_streak = 0

                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç –ø–æ id
                        existing = session.query(FeedbackStorage).filter_by(id=feedback_id).first()
                        if existing:
                            for attr, val in parsed.items():
                                setattr(existing, attr, val)
                            existing.related_month = task.related_month
                        else:
                            session.add(FeedbackStorage(id=feedback_id, related_month=task.related_month, **parsed))

                        success_count += 1

                    except Exception as row_err:
                        error_count += 1
                        log_error(self.log_file, "import_feedbacks_to_update", task.name_of_process, "row_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")

                session.commit()
                log_success(self.log_file, "import_feedbacks_to_update", task.name_of_process, "imported", f"‚úÖ [{task.name_of_process}] –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∏–¥–±–µ–∫–æ–≤: {success_count}, –æ—à–∏–±–æ–∫: {error_count}")
                total_success += success_count
                total_error += error_count

                # --- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ DealerMonthlyStatus ---
                log_info(self.log_file, "import_feedbacks_to_update", task.name_of_process, "dealer_status_update", f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ DealerMonthlyStatus –ø–æ —Ñ–∏–¥–±–µ–∫–∞–º –¥–ª—è {task.related_month}...")
                dealers = session.query(DealerMonthlyStatus).filter_by(related_month=task.related_month).all()
                output_data = []

                for dealer in dealers:
                    feedbacks = session.query(FeedbackStorage).filter_by(
                        dealer_name=dealer.dealer_name,
                        related_month=dealer.related_month
                    ).all()

                    if not feedbacks:
                        dealer.feedback_status = True
                        output_data.append([dealer.dealer_name, "‚úÖ"])
                        continue

                    if any(f.forwarded_feedback is None for f in feedbacks):
                        dealer.feedback_status = False
                        output_data.append([dealer.dealer_name, "‚ùå"])
                    else:
                        dealer.feedback_status = True
                        output_data.append([dealer.dealer_name, "‚úÖ"])

                session.commit()
                log_success(self.log_file, "import_feedbacks_to_update", task.name_of_process, "dealer_status_updated", f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ DealerMonthlyStatus: {len(output_data)} –∑–∞–ø–∏—Å–µ–π")

                # --- –í—ã–≥—Ä—É–∑–∫–∞ –≤ Google Sheets ---
                try:
                    batch_data = [{
                        "range": f"{task.target_page_name}!{task.target_page_area}",
                        "values": output_data
                    }]
                    success, error = batch_update(
                        service=self.service,
                        spreadsheet_id=task.target_doc_id,
                        batch_data=batch_data,
                        token_name=self.token_name,
                        update_group="feedback_status_update",
                        log_file=self.log_file
                    )
                    if success:
                        log_success(self.log_file, "import_feedbacks_to_update", task.name_of_process, "sheet_upload", f"üì§ –í—ã–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ Google Sheet –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {task.target_page_name} ({task.target_page_area})")
                    else:
                        log_error(self.log_file, "import_feedbacks_to_update", task.name_of_process, "sheet_upload_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –≤ Google Sheet: {error}")
                except Exception as gs_err:
                    log_error(self.log_file, "import_feedbacks_to_update", task.name_of_process, "sheet_upload_exception", f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –≤ Google Sheet: {gs_err}")

            except Exception as e:
                session.rollback()
                log_error(self.log_file, "import_feedbacks_to_update", task.name_of_process, "task_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {e}")

        log_success(self.log_file, "import_feedbacks_to_update", None, "imported_total", f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∏–¥–±–µ–∫–æ–≤ –≤—Å–µ–≥–æ: {total_success}, –æ—à–∏–±–æ–∫: {total_error}")
        log_info(self.log_file, "import_feedbacks_to_update", None, "finish", "üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ñ–∞–∑—ã feedback_status_update.")

################################################################################################
# –ò–º–ø–æ—Ä—Ç Schedule OT
################################################################################################

    def import_schedule_OT_to_update(self, tasks, session):
        total_new = 0
        total_updated = 0

        for task in tasks:
            new_entries = 0
            updated_entries = 0
            try:
                values = task.values_json
                if not values or not isinstance(values, list):
                    log_error(self.log_file, "import_schedule_OT_to_update", task.name_of_process, "empty_values", f"‚ùå values_json –ø—É—Å—Ç –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω –≤ –∑–∞–¥–∞—á–µ {task.name_of_process}")
                    continue

                related_month = task.related_month.replace(day=1)
                existing_records = session.query(ScheduleOT).filter_by(related_month=related_month).all()
                existing_lookup = {
                    (rec.dealer_name.strip(), rec.date): rec
                    for rec in existing_records if rec.dealer_name
                }

                for row in values:
                    if not row or not isinstance(row, list) or len(row) < 2:
                        continue

                    dealer_name = row[0]
                    if not dealer_name or not isinstance(dealer_name, str):
                        continue

                    dealer_name = dealer_name.strip()

                    for col_idx, shift in enumerate(row[1:], start=1):
                        shift = (shift or "").strip()
                        if shift in {"", "-", "/"}:
                            continue

                        try:
                            shift_date = related_month.replace(day=col_idx)
                        except ValueError:
                            continue

                        key = (dealer_name, shift_date)

                        if key in existing_lookup:
                            record = existing_lookup[key]
                            if record.shift_type != shift:
                                record.shift_type = shift
                                updated_entries += 1
                        else:
                            exists = session.query(ScheduleOT).filter_by(
                                dealer_name=dealer_name,
                                date=shift_date,
                                related_month=related_month
                            ).first()
                            if exists:
                                continue
                            session.add(ScheduleOT(
                                date=shift_date,
                                dealer_name=dealer_name,
                                shift_type=shift,
                                related_month=related_month
                            ))
                            new_entries += 1

                session.commit()
                log_success(self.log_file, "import_schedule_OT_to_update", task.name_of_process, "imported", f"üìÖ [{task.name_of_process}] ScheduleOT ‚Äî –Ω–æ–≤—ã—Ö: {new_entries}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_entries}")
                total_new += new_entries
                total_updated += updated_entries

            except Exception as e:
                session.rollback()
                log_error(self.log_file, "import_schedule_OT_to_update", task.name_of_process, "task_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {e}")

        log_success(self.log_file, "import_schedule_OT_to_update", None, "imported_total", f"‚úÖ ScheduleOT –∏—Ç–æ–≥–æ ‚Äî –Ω–æ–≤—ã—Ö: {total_new}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {total_updated}")

    def import_qa_list_to_update(self, qa_list_update, session):
        """
        –ò–º–ø–æ—Ä—Ç QA List –≤ –ë–î —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏.
        """
        total_success = 0
        total_error = 0

        for task in qa_list_update:
            success_count = 0
            error_count = 0
            try:
                sheet = task.raw_values_json
                if not self._validate_sheet(sheet):
                    log_warning(self.log_file, "import_qa_list_to_update", task.name_of_process, "empty_sheet", f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π sheet –≤ –∑–∞–¥–∞—á–µ: {task.name_of_process}")
                    continue

                page_name = task.source_page_name
                for row_index, row in enumerate(sheet[1:], start=2):  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    # –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ dealer_name –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–π
                    if not row or len(row) < 2 or not row[0] or not str(row[0]).strip():
                        log_warning(self.log_file, "import_qa_list_to_update", task.name_of_process, "invalid_row", f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row_index} –±–µ–∑ dealer_name –∏–ª–∏ —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–º –¥–∞–Ω–Ω—ã—Ö –≤ {page_name}")
                        continue

                    if not self._is_valid_qa_row(row):
                        log_warning(self.log_file, "import_qa_list_to_update", task.name_of_process, "invalid_row", f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –Ω–µ–ø–æ–ª–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ {row_index} –≤ {page_name}")
                        continue

                    try:
                        with session.no_autoflush:
                            exists = session.query(QaList).filter_by(
                                dealer_name=row[0]
                            ).first()
                            if exists:
                                qa_item = self._parse_qa_list_row(task, row, row_index, page_name)
                                for attr in qa_item.__table__.columns.keys():
                                    if attr != "id":
                                        setattr(exists, attr, getattr(qa_item, attr))
                            else:
                                qa_item = self._parse_qa_list_row(task, row, row_index, page_name)
                                if qa_item:
                                    session.add(qa_item)
                                    success_count += 1
                    except Exception as row_err:
                        log_error(self.log_file, "import_qa_list_to_update", task.name_of_process, "row_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")
                        error_count += 1

                session.commit()
                log_success(self.log_file, "import_qa_list_to_update", task.name_of_process, "imported", f"‚úÖ [{task.name_of_process}] –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ QA –∑–∞–ø–∏—Å–µ–π: {success_count}, –æ—à–∏–±–æ–∫: {error_count}")
                total_success += success_count
                total_error += error_count

            except Exception as task_err:
                session.rollback()
                log_error(self.log_file, "import_qa_list_to_update", task.name_of_process, "task_fail", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ {task.name_of_process}: {task_err}")

        log_success(self.log_file, "import_qa_list_to_update", None, "imported_total", f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ QA –∑–∞–ø–∏—Å–µ–π –≤—Å–µ–≥–æ: {total_success}, –æ—à–∏–±–æ–∫: {total_error}")

    def _build_batch_data(self, group_tasks):
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch_update –¥–ª—è –≥—Ä—É–ø–ø—ã –∑–∞–¥–∞—á.
        """
        batch_data = []
        for task in group_tasks:
            if not task.values_json:
                continue
            batch_data.append({
                "range": f"{task.target_page_name}!{task.target_page_area}",
                "values": task.values_json
            })
        return batch_data

    def _parse_qa_list_row(self, task, row, row_index, page_name):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É QA List –≤ –æ–±—ä–µ–∫—Ç QaList.
        """
        # –ü—Ä–∏–º–µ—Ä: row = [dealer_name, VIP, GENERIC, LEGENDZ, GSBJ, TURKISH, TRISTAR, TritonRL, QA_comment, Male, BJ, BC, RL, DT, HSB, swBJ, swBC, swRL, SH, gsDT]
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–µ–π –∏ –ø–æ—Ä—è–¥–æ–∫ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ QaList!
        return QaList(
            dealer_name=row[0].strip() if row[0] else "",
            VIP=row[1] if len(row) > 1 else "",
            GENERIC=row[2] if len(row) > 2 else "",
            LEGENDZ=row[3] if len(row) > 3 else "",
            GSBJ=row[4] if len(row) > 4 else "",
            TURKISH=row[5] if len(row) > 5 else "",
            TRISTAR=row[6] if len(row) > 6 else "",
            TritonRL=row[7] if len(row) > 7 else "",
            QA_comment=row[8] if len(row) > 8 else "",
            Male=row[9] if len(row) > 9 else "",
            BJ=row[10] if len(row) > 10 else "",
            BC=row[11] if len(row) > 11 else "",
            RL=row[12] if len(row) > 12 else "",
            DT=row[13] if len(row) > 13 else "",
            HSB=row[14] if len(row) > 14 else "",
            swBJ=row[15] if len(row) > 15 else "",
            swBC=row[16] if len(row) > 16 else "",
            swRL=row[17] if len(row) > 17 else "",
            SH=row[18] if len(row) > 18 else "",
            gsDT=row[19] if len(row) > 19 else "",
        )
