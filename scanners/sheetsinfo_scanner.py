# scanners/sheetsinfo_scanner.py

import os
import time
import sqlite3
import json
from collections import defaultdict
from googleapiclient.errors import HttpError
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request

from bot.settings_access import is_scanner_enabled
from core.config import SHEETSINFO_LOG, SHEETSINFO_TOKEN, SHEETINFO_INTERVAL, DB_PATH
from core.data import load_sheetsinfo_tasks
from database.database import insert_usage
from utils.logger import log_to_file, log_separator, log_section

class SheetsInfoScanner:
    def __init__(self, conn, service, doc_id_map):
        self.conn = conn
        self.service = service
        self.doc_id_map = doc_id_map
        self.tasks = []
        self.log_file = SHEETSINFO_LOG
        self.keep_running = True

    def run(self):

        while True:
            try:
                
                if not is_scanner_enabled("sheets_scanner"):
                    log_to_file(self.log_file, "‚è∏ –°–∫–∞–Ω–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω (sheets_scanner). –û–∂–∏–¥–∞–Ω–∏–µ...")
                    time.sleep(10)
                    continue
                log_to_file(self.log_file, "üîÑ –ù–æ–≤—ã–π —Ü–∏–∫–ª —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è SheetsInfo")

                try:
                    self.check_and_refresh_token(SHEETSINFO_TOKEN)
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {e}")
                    raise

                try:
                    self.load_tasks()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–¥–∞—á: {e}")
                    raise

                try:
                    self.scan_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
                    raise

                try:
                    self.process_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                    raise

                try:
                    self.update_phase()
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
                    raise

                time.sleep(60)

            except Exception as e:
                log_separator(self.log_file)
                log_to_file(self.log_file, f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                time.sleep(10)

############################################################################################
# –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
############################################################################################

    def check_and_refresh_token(self, token_path):
        log_section("üîê –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞", self.log_file)

        if not os.path.exists(token_path):
            log_to_file(self.log_file, f"‚ùå –§–∞–π–ª —Ç–æ–∫–µ–Ω–∞ {token_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            raise FileNotFoundError(f"{token_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

        creds = Credentials.from_authorized_user_file(token_path)

        if creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
                with open(token_path, "w", encoding="utf-8") as f:
                    f.write(creds.to_json())

                log_to_file(self.log_file, f"üîÑ –¢–æ–∫–µ–Ω –æ–±–Ω–æ–≤–ª—ë–Ω: {token_path}")

                # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∞–∫—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
                insert_usage(
                    token=SHEETSINFO_TOKEN,
                    count=1,
                    scan_group="token_refresh",
                    success=True
                )

            except Exception as e:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ {token_path}: {e}")

                # ‚ùå –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
                insert_usage(
                    token=SHEETSINFO_TOKEN,
                    count=1,
                    scan_group="token_refresh",
                    success=False
                )
                raise
        else:
            log_to_file(self.log_file, f"‚úÖ –¢–æ–∫–µ–Ω {token_path} –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω.")

#############################################################################################
# –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ –ë–î
#############################################################################################

    def load_tasks(self):
        log_section("üß© üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ SheetsInfo", self.log_file)
        self.tasks = load_sheetsinfo_tasks(self.conn)

        if not self.tasks:
            log_section("‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ SheetsInfo.", self.log_file)
            return

        log_section(f"üîÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.tasks)} –∑–∞–¥–∞—á.", self.log_file)
        for task in self.tasks:
            task.assign_doc_ids(self.doc_id_map)

#############################################################################################
# –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
#############################################################################################

    def scan_phase(self):
        log_section("üîç –§–∞–∑–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è", self.log_file)

        if not self.tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return

        ready_tasks = [task for task in self.tasks if task.is_ready_to_scan()]
        if not ready_tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.")
            return

        log_to_file(self.log_file, f"üîé –ù–∞–π–¥–µ–Ω–æ {len(ready_tasks)} –∑–∞–¥–∞—á, –≥–æ—Ç–æ–≤—ã—Ö –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é:")

        scan_groups = defaultdict(list)
        for task in ready_tasks:
            if not task.assign_doc_ids(self.doc_id_map):
                log_to_file(self.log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å doc_id. –ü—Ä–æ–ø—É—Å–∫.")
                continue
            scan_groups[task.scan_group].append(task)

        for scan_group, group_tasks in scan_groups.items():
            log_separator(self.log_file)
            log_to_file(self.log_file, f"üìò –û–±—Ä–∞–±–æ—Ç–∫–∞ scan_group: {scan_group} ({len(group_tasks)} –∑–∞–¥–∞—á)")

            if not group_tasks:
                log_to_file(self.log_file, "‚ö™ –í –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∑–∞–¥–∞—á.")
                continue

            doc_id = group_tasks[0].source_doc_id
            unique_sheet_names = set(task.source_page_name for task in group_tasks)
            log_to_file(self.log_file, f"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–∏—Å—Ç–æ–≤: {unique_sheet_names}")

            exists_map = {}
            for sheet_name in unique_sheet_names:
                exists_map[sheet_name] = self.check_sheet_exists(doc_id, sheet_name)
                log_to_file(self.log_file, f"{'‚úÖ' if exists_map[sheet_name] else '‚ö†Ô∏è'} –õ–∏—Å—Ç '{sheet_name}' {'—Å—É—â–µ—Å—Ç–≤—É–µ—Ç' if exists_map[sheet_name] else '–Ω–µ –Ω–∞–π–¥–µ–Ω'}.")

            valid_tasks = []
            for task in group_tasks:
                sheet_name = task.source_page_name
                if exists_map.get(sheet_name):
                    log_to_file(self.log_file, f"‚û°Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º '{sheet_name}' –¥–ª—è –∑–∞–¥–∞—á–∏ {task.name_of_process}.")
                    valid_tasks.append(task)
                else:
                    log_to_file(self.log_file, f"‚õî –ü—Ä–æ–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ {task.name_of_process}: –ª–∏—Å—Ç '{sheet_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                    task.update_after_scan(success=False) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ö–ª–∞—Å—Å–µ
                    self.update_task_scan_fields(task) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î

            if not valid_tasks:
                log_to_file(self.log_file, f"‚ö™ –í—Å–µ –∑–∞–¥–∞—á–∏ –≥—Ä—É–ø–ø—ã {scan_group} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ batchGet.")
                continue

            range_to_tasks = defaultdict(list)
            for task in valid_tasks:
                range_str = f"{task.source_page_name}!{task.source_page_area}"
                range_to_tasks[range_str].append(task)

            ranges = list(range_to_tasks.keys())

            log_to_file(self.log_file, "")

            log_to_file(self.log_file, f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ batchGet –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç {task.source_table_type} —Å {len(ranges)} —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏:")
            for r in ranges:
                log_to_file(self.log_file, f"   ‚Ä¢ {r}")

            response_data = self.batch_get(self.service, doc_id, ranges, scan_group, self.log_file)
            if not response_data:
                log_to_file(self.log_file, "‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç batchGet. –í—Å–µ –∑–∞–¥–∞—á–∏ –±—É–¥—É—Ç –æ—Ç–º–µ—á–µ–Ω—ã –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—ã–µ.")
                for task in valid_tasks:
                    task.update_after_scan(success=False) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ö–ª–∞—Å—Å–µ
                    self.update_task_scan_fields(task) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                continue

            normalized_response = {}
            for k, v in response_data.items():
                clean_key = k.replace("'", "")
                if "!" in clean_key:
                    sheet_name, cells_range = clean_key.split("!", 1)
                    normalized_response[(sheet_name.strip(), cells_range.strip())] = v

            log_to_file(self.log_file, "")
            log_to_file(self.log_file, f"üì• –ü–æ–ª—É—á–µ–Ω—ã –¥–∏–∞–ø–∞–∑–æ–Ω—ã: {list(normalized_response.keys())}")

            for task in valid_tasks:
                expected_sheet = task.source_page_name.strip()
                expected_area_start = task.source_page_area.split(":")[0].strip()
                matched_values = None
                
                for (sheet_name, cells_range), values in normalized_response.items():
                    if sheet_name == expected_sheet and cells_range.startswith(expected_area_start):
                        matched_values = values
                        break

                if matched_values:
                    task.raw_values_json = matched_values #–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ raw_values_json
                    task.update_after_scan(success=True) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ö–ª–∞—Å—Å–µ
                    self.update_task_scan_fields(task) #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                    log_to_file(self.log_file, f"‚úÖ [Task {task.name_of_process}] –ù–∞–π–¥–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω {sheet_name}!{cells_range}, —Å—Ç—Ä–æ–∫: {len(matched_values)}")
                else:
                    task.update_after_scan(success=False)
                    self.update_task_scan_fields(task)
                    log_to_file(self.log_file, f"‚ö†Ô∏è [Task {task.name_of_process}] –î–∏–∞–ø–∞–∑–æ–Ω {expected_sheet}!{task.source_page_area} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç.")

    def check_sheet_exists(self, spreadsheet_id, sheet_name):
        try:
            metadata = self.service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
            sheets = metadata.get('sheets', [])
            for sheet in sheets:
                title = sheet.get('properties', {}).get('title')
                if title == sheet_name:
                    return True
            return False
        except Exception as e:
            log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ª–∏—Å—Ç–∞ –≤ {spreadsheet_id}: {e}")
            return False
        
    def update_task_scan_fields(self, task):
        cursor = self.conn.cursor()
        table_name = "SheetsInfo"

        cursor.execute(f"""
            UPDATE {table_name}
            SET
                last_scan = ?,
                scan_quantity = ?,
                scan_failures = ?
            WHERE id = ?
        """, (
            task.last_scan.isoformat() if task.last_scan else None,
            task.scan_quantity,
            task.scan_failures,
            task.id
        ))

        log_to_file(self.log_file, f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤ –ë–î [Task {task.name_of_process}] ‚Üí proceed={task.proceed} ‚Üí changed={task.changed}, hash={task.hash}")
        self.conn.commit()

    def batch_get(self, service, spreadsheet_id, ranges, scan_group, log_file, retries=5, delay_seconds=5):
        attempt = 0
        success = False

        while attempt < retries:
            try:
                log_to_file(log_file, f"üì° –ü—ã—Ç–∞—é—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å batchGet (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}) –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {spreadsheet_id}")

                result = service.spreadsheets().values().batchGet(
                    spreadsheetId=spreadsheet_id,
                    ranges=ranges,
                    majorDimension="ROWS"
                ).execute()

                value_ranges = result.get("valueRanges", [])
                data = {vr.get("range", ""): vr.get("values", []) for vr in value_ranges}

                log_to_file(log_file, f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π batchGet. –ü–æ–ª—É—á–µ–Ω–æ {len(data)} –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤.")
                success = True
                break  # –í—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

            except HttpError as e:
                status_code = e.resp.status
                log_to_file(log_file, f"‚ùå HttpError {status_code} –ø—Ä–∏ batchGet: {e}")

                if status_code in (429, 500, 503):
                    attempt += 1
                    log_to_file(log_file, f"‚è≥ –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay_seconds} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(delay_seconds)
                elif status_code == 401:
                    log_to_file(log_file, "üîí –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (401). –ü—Ä–µ—Ä—ã–≤–∞—é batchGet.")
                    break
                else:
                    break

            except Exception as e:
                if any(x in str(e).lower() for x in ["ssl", "handshake", "decryption", "timed out"]):
                    attempt += 1
                    log_to_file(log_file, f"‚è≥ –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ '{e}', –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay_seconds} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(delay_seconds)
                else:
                    log_to_file(log_file, f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ batchGet: {e}")
                    break

        # ‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
        insert_usage(
            token=SHEETSINFO_TOKEN,
            count=attempt + 1,           # total –ø–æ–ø—ã—Ç–æ–∫, –≤–∫–ª—é—á–∞—è —Ñ–∏–Ω–∞–ª—å–Ω—É—é
            scan_group=scan_group,
            success=success
        )

        if success:
            return data
        else:
            log_to_file(log_file, "‚ùå batchGet –∑–∞–≤–µ—Ä—à—ë–Ω –Ω–µ—É–¥–∞—á–Ω–æ.")
            return {}


#############################################################################################
# –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
#############################################################################################

    def process_phase(self):
        log_section("üõ†Ô∏è –§–∞–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏", self.log_file)

        if not self.tasks:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            return

        for task in self.tasks:
            if task.scanned == 0:
                log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –ó–∞–¥–∞—á–∞ –Ω–µ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞. –ü—Ä–æ–ø—É—Å–∫.")
                continue

            try:
                log_to_file(self.log_file, f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ [Task {task.name_of_process}]...")

                try:
                    task.process_raw_value() # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ values_json
                    
                    log_to_file(self.log_file, f"üì¶ [Task {task.name_of_process}] –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(task.values_json)} —Å—Ç—Ä–æ–∫.")
                    # for i, row in enumerate(task.values_json[:5]):
                    #     log_to_file(self.log_file, f"      [{i+1}] {row}")
                    # if len(task.values_json) > 5:
                    #     log_to_file(self.log_file, f"      ...–µ—â—ë {len(task.values_json) - 5} —Å—Ç—Ä–æ–∫ —Å–∫—Ä—ã—Ç–æ")
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –≤ process_raw_value: {e}")
                    continue

                try:
                    task.check_for_update()

                    if task.changed:
                        log_to_file(self.log_file, "üîÅ –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã ‚Äî –∑–∞–¥–∞—á–∞ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")
                        self.update_task_process_fields(task) # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                        log_to_file(self.log_file, f"‚úÖ [Task {task.name_of_process}] –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ –ë–î.\n")
                    else:
                        log_to_file(self.log_file, "‚ö™ –ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n")
                except Exception as e:
                    log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –≤ check_for_update: {e}")
                    continue

            except Exception as e:
                log_to_file(self.log_file, f"‚ùå [Task {task.name_of_process}] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

    def update_task_process_fields(self, task):
        cursor = self.conn.cursor()
        table = "SheetsInfo"
        cursor.execute(f"""
            UPDATE {table}
            SET
                hash = ?,
                values_json = ?
            WHERE id = ?
        """, (
            task.hash,
            json.dumps(task.values_json) if task.values_json else None,
            task.id
        ))
        log_to_file(self.log_file, f"üíæ –û–±–Ω–æ–≤–ª—ë–Ω values_json –∏ hash –¥–ª—è –∑–∞–¥–∞—á–∏ {task.name_of_process}")
        self.conn.commit()

#############################################################################################
# –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
#############################################################################################

    def update_phase(self):
        log_section("üîº –§–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è", self.log_file)
        # time.sleep(SHEETINFO_INTERVAL)
        # return  # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        has_tasks_changes = any(task.changed for task in self.tasks if task.update_group != "update_mistakes_in_db")
        log_to_file(self.log_file, f"üîº –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∑–∞–¥–∞—á–∞—Ö: {has_tasks_changes}")
        tasks_to_update = [task for task in self.tasks if task.values_json and task.update_group != "update_mistakes_in_db" and has_tasks_changes]
        log_to_file(self.log_file, f"üîº –ó–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(tasks_to_update)}")


        has_mistakes_changes = any(task.changed for task in self.tasks if task.update_group == "update_mistakes_in_db")
        log_to_file(self.log_file, f"üîº –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –æ—à–∏–±–∫–∞—Ö: {has_mistakes_changes}")
        mistakes_to_update = [task for task in self.tasks if task.values_json and task.update_group == "update_mistakes_in_db" and has_mistakes_changes]
        log_to_file(self.log_file, f"üîº –û—à–∏–±–æ–∫ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(mistakes_to_update)}")

        # if tasks_to_update:
        #         try:
        #             self.import_tasks_to_update(tasks_to_update)
        #         except Exception as e:
        #             log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ tasks_to_update: {e}")

        if mistakes_to_update:
            try:
                self.import_mistakes_to_update(mistakes_to_update)
            except Exception as e:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ mistakes_to_update: {e}")
        if not tasks_to_update and not mistakes_to_update:
            log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è. –ü—Ä–æ–ø—É—Å–∫.")
            return
        else:
            log_to_file(self.log_file, "üîº –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        
        time.sleep(SHEETINFO_INTERVAL)

##############################################################################################
# –ò–º–ø–æ—Ä—Ç –û–±—ã—á–Ω—ã—Ö –∑–∞–¥–∞—á 
##############################################################################################

    def import_tasks_to_update(self, tasks_to_update):

        log_to_file(self.log_file, f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã tasks_to_update. –ó–∞–¥–∞—á –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏: {len(tasks_to_update)}.")

        tasks_by_update_group = defaultdict(list)
        for task in tasks_to_update:
            tasks_by_update_group[task.update_group].append(task)

        for update_group, group_tasks in tasks_by_update_group.items():
            log_section(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {update_group} ({len(group_tasks)} –∑–∞–¥–∞—á).", self.log_file)

            doc_id = group_tasks[0].target_doc_id

            batch_data = []
            for task in group_tasks:
                if not task.values_json:
                    log_to_file(self.log_file, f"‚ö™ [Task {task.name_of_process}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏, –ø—Ä–æ–ø—É—Å–∫.")
                    continue

                batch_data.append({
                    "range": f"{task.target_page_name}!{task.target_page_area}",
                    "values": task.values_json
                })

            if not batch_data:
                log_to_file(self.log_file, "‚ö™ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è batchUpdate –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ.")
                continue

            success, error = self.batch_update(self.service, doc_id, batch_data, update_group, self.log_file)

            if success:
                for task in group_tasks:
                    task.update_after_upload(success=True)
                    self.update_task_update_fields(task)
                    insert_usage(
                        token=SHEETSINFO_TOKEN,
                        count=1,
                        scan_group=update_group,
                        success=True
                    )
                log_to_file(self.log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã {update_group} ({len(group_tasks)} –∑–∞–¥–∞—á).")
            else:
                log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ batchUpdate: {error}")
                log_to_file(self.log_file, "üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ—Ç–ø—Ä–∞–≤–∫—É –∑–∞–¥–∞—á.")

                for task in group_tasks:
                    if not task.values_json:
                        continue

                    single_data = [{
                        "range": f"{task.target_page_name}!{task.target_page_area}",
                        "values": task.values_json
                    }]
                    single_success, single_error = self.batch_update(self.service, doc_id, single_data, update_group, self.log_file)

                    insert_usage(
                        token=SHEETSINFO_TOKEN,
                        count=1,
                        scan_group=update_group,
                        success=single_success
                    )

                    if single_success:
                        task.update_after_upload(success=True)
                        log_to_file(self.log_file, f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ [Task {task.name_of_process}] –æ—Ç–¥–µ–ª—å–Ω–æ.")
                        log_separator(self.log_file)
                        log_to_file(self.log_file, "" * 100)
                    else:
                        task.update_after_upload(success=False)
                        log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è [Task {task.name_of_process}] –æ—Ç–¥–µ–ª—å–Ω–æ: {single_error}")
                        log_separator(self.log_file)
                        log_to_file(self.log_file, "" * 100)

                    self.update_task_update_fields(task)

                    log_to_file(self.log_file, f"üíæ –û–±–Ω–æ–≤–ª—ë–Ω values_json –∏ hash –¥–ª—è –∑–∞–¥–∞—á–∏ {task.name_of_process}")

###############################################################################################
# –ò–º–ø–æ—Ä—Ç –û—à–∏–±–æ–∫ –≤ –ë–î
###############################################################################################
    @staticmethod
    def get_floor_by_table_name(table_name: str, floor_map: dict) -> str:
        for floor, tables in floor_map.items():
            if table_name in tables:
                return floor
        return "UNKNOWN"

    @staticmethod
    def get_max_last_row(conn, table_name):
        cursor = conn.cursor()
        cursor.execute("SELECT MAX(last_row) FROM MistakeStorage WHERE table_name = ?", (table_name,))
        result = cursor.fetchone()
        return result[0] if result and result[0] is not None else 0

    def import_mistakes_to_update(self, mistakes_to_update):
        log_to_file(self.log_file, f"üîÑ –ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã mistakes_to_update. –ó–∞–¥–∞—á –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏: {len(mistakes_to_update)}.")

        floor_list = {
            "VIP": ["vBJ2", "vBJ3", "gBC1", "vBC3", "vBC4", "vHSB1", "vDT1", "gsRL1", "swBC1", "swRL1"],
            "TURKISH": ["tBJ1", "tBJ2", "tRL1"],
            "GENERIC": ["gBJ1", "gBJ3", "gBJ4", "gBJ5", "gBC2", "gBC3", "gBC4", "gBC5", "gBC6", "gRL1", "gRL2"],
            "GSBJ": ["gsBJ1", "gsBJ2", "gsBJ3", "gsBJ4", "gsBJ5", "gRL3"],
            "LEGENDZ": ["lBJ1", "lBJ2", "lBJ3"]
        }

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        try:
            for task in mistakes_to_update:
                sheet = task.raw_values_json
                page_name = task.source_page_name
                floor = self.get_floor_by_table_name(page_name, floor_list)
                max_row_in_db = self.get_max_last_row(conn, page_name)

                for row_index, row in enumerate(sheet[1:], start=2):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    if row_index <= max_row_in_db:
                        continue

                    # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
                    if not row or len(row) < 8:
                        log_to_file(self.log_file, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ {row_index} –∏–∑ {page_name}: {row}")
                        continue

                    try:
                        is_cancel = 1 if str(row[5]).strip().lower() == "cancel" else 0

                        cursor.execute("""
                            INSERT INTO MistakeStorage (
                                floor, table_name, date, time, game_id, mistake, type,
                                is_cancel, dealer, sm, last_row
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            floor,
                            page_name,
                            row[0],  # date
                            row[1],  # time
                            row[2],  # game_id
                            row[3],  # mistake
                            row[4],  # type
                            is_cancel,
                            row[6],  # dealer
                            row[7],  # sm
                            row_index
                        ))

                    except Exception as row_err:
                        log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏ {row_index} –∏–∑ {page_name}: {row_err}. –°—Ç—Ä–æ–∫–∞: {row}")
                        continue  # –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –µ–¥–µ–º –¥–∞–ª—å—à–µ

            conn.commit()
            log_to_file(self.log_file, "‚úÖ –í—Å–µ –æ—à–∏–±–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.")

        except Exception as task_err:
            log_to_file(self.log_file, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ mistakes_to_update: {task_err}")

        finally:
            conn.close()
            log_to_file(self.log_file, "üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ñ–∞–∑—ã mistakes_to_update.")


###############################################################################################
# batchUpdate –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ Google Sheets
###############################################################################################

    def batch_update(self, service, spreadsheet_id, batch_data, update_group, log_file, retries=3, delay_seconds=10):
        success = False
        attempt = 0

        while attempt < retries:
            try:
                log_to_file(log_file, f"üì§ –ü—ã—Ç–∞—é—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å batchUpdate (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}) –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {spreadsheet_id}")

                service.spreadsheets().values().batchUpdate(
                    spreadsheetId=spreadsheet_id,
                    body={
                        "valueInputOption": "USER_ENTERED",
                        "data": batch_data
                    }
                ).execute()

                log_to_file(log_file, "‚úÖ –£—Å–ø–µ—à–Ω—ã–π batchUpdate.")
                success = True
                break  # –∑–∞–≤–µ—Ä—à–∏–ª–∏ —É—Å–ø–µ—à–Ω–æ

            except HttpError as e:
                status = e.resp.status
                log_to_file(log_file, f"‚ùå HTTP {status}: {e}")

                if status in [429, 500, 503]:
                    attempt += 1
                    log_to_file(log_file, f"‚è≥ –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay_seconds} —Å–µ–∫...")
                    time.sleep(delay_seconds)
                else:
                    break

            except Exception as e:
                log_to_file(log_file, f"‚ùå –û—à–∏–±–∫–∞: {e}")
                break

        # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞
        insert_usage(
            token=SHEETSINFO_TOKEN,
            count=attempt + 1,
            update_group=update_group,
            success=success
        )

        if success:
            return True, None
        else:
            return False, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫" if attempt == retries else "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"

    def update_task_update_fields(self, task):
        cursor = self.conn.cursor()
        table = "SheetsInfo"
        cursor.execute(f"""
            UPDATE {table}
            SET
                last_update = ?,
                update_quantity = ?,
                update_failures = ?
            WHERE id = ?
        """, (
            task.last_update.isoformat() if task.last_update else None,
            task.update_quantity,
            task.update_failures,
            task.id
        ))
        self.conn.commit()